{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning Tuning_Hats:\n",
    "  * model parameter and other information can be found below:\n",
    "     * [source](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)\n",
    "     \n",
    "  * base_model: use vgg16 and freeze at bottleneck layer (stop right before flatten layer) \n",
    "  * top_model: tune dense layers (parameters are inspired by source)\n",
    "     * batch_size 16 seems to work best for small data set \n",
    "\n",
    "##### warnings: make sure to restart kernel in between running different model tuning \n",
    "  \n",
    "---\n",
    "#### This cell is required in order to use GPU for running the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0829 12:48:19.973269 140460642596672 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0829 12:48:19.974265 140460642596672 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "                                    # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
    "keras.backend.get_session().run(tf.global_variables_initializer())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import optimizers\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Import train_df and test_df for hats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('../pickle_files/train_df_hat.pkl')\n",
    "test_df = pd.read_pickle('../pickle_files/test_df_hat.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get bottleneck features to tune top models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_bottleneck_features(train_df, test_df, label, batch_size):\n",
    "    '''\n",
    "    inputs:\n",
    "    train_df, test_df: train and test dataframes saved in pickle_files folder\n",
    "    label: a string, eyewear, hat, or beard\n",
    "    batch_size: process images in batches\n",
    "    outputs:\n",
    "    saves bottleneck features inside folder tuning_data as npy file\n",
    "    '''\n",
    "    # intialize the vgg16 model \n",
    "    # make sure not to train the top layers \n",
    "    base_model = VGG16(weights = 'imagenet', include_top = False)\n",
    "    # create train_generator and test_generator to get bottleneck inputs for train and test df \n",
    "    # remove zoom range for hats\n",
    "    datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        shear_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "    # make sure shuffle is False so we know the label follows the sequence of the dataframe \n",
    "    # so we can tune top_model \n",
    "    train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory='../data/pics',\n",
    "    x_col='pic_id',\n",
    "    y_col=label,\n",
    "    batch_size=batch_size,\n",
    "    shuffle = False,\n",
    "    target_size=(150,150),\n",
    "    class_mode = None)\n",
    "    # get features saved as .npy in tunign_data folder \n",
    "    bottleneck_features_train = base_model.predict_generator(\n",
    "        train_generator, train_df.shape[0]//batch_size)\n",
    "    np.save(open('../tuning_data/bottleneck_features_train_hat.npy','wb'),\n",
    "           bottleneck_features_train)\n",
    "    \n",
    "    test_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory='../data/pics',\n",
    "    x_col='pic_id',\n",
    "    y_col=label,\n",
    "    batch_size=batch_size,\n",
    "    shuffle = False,\n",
    "    target_size=(150,150),\n",
    "    class_mode = None)\n",
    "    bottleneck_features_test = base_model.predict_generator(\n",
    "        test_generator, test_df.shape[0]//batch_size)\n",
    "    np.save(open('../tuning_data/bottleneck_features_test_hat.npy','wb'),\n",
    "           bottleneck_features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save bottleneck_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0829 12:48:35.696041 140460642596672 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0829 12:48:35.697094 140460642596672 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0829 12:48:35.699244 140460642596672 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0829 12:48:35.714792 140460642596672 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 408 validated image filenames.\n",
      "Found 102 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "save_bottleneck_features(train_df,test_df,'hat',16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick tuning of top models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_top_model(train_df, test_df, epoch, batch_size, label):\n",
    "    '''\n",
    "    inputs:\n",
    "    train_df, test_df: dataframes saved in pickle_files to generate train and test labels \n",
    "    epoch: num of epochs in fit \n",
    "    batch_size: same as image generator batch size \n",
    "    label: a string, eyewear, hat, or beard\n",
    "    output:\n",
    "    saves model weights in a folder \n",
    "    '''\n",
    "    train_data = np.load(open('../tuning_data/bottleneck_features_train_hat.npy','rb'))\n",
    "    # make sure train_data and train_label have same num of samples\n",
    "    train_label = np.array(train_df[label].map({'not_'+label:0, label:1}))[:-(train_df.shape[0]%batch_size)]\n",
    "    \n",
    "    test_data = np.load(open('../tuning_data/bottleneck_features_test_hat.npy','rb'))\n",
    "    test_label = np.array(test_df[label].map({'not_'+label:0, label:1}))[:-(test_df.shape[0]%batch_size)]\n",
    "    \n",
    "    # build top model\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='rmsprop',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    # checkpoint for best weights \n",
    "    filepath=\"../tuning_data/best_bottleneck_vgg_model_hat.h5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    \n",
    "    model.fit(train_data, train_label,\n",
    "             epochs=epoch,\n",
    "             batch_size=batch_size,\n",
    "             validation_data=(test_data,test_label),\n",
    "             callbacks=callbacks_list\n",
    "    del model\n",
    "    keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run train_top_model and save results in tuning_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0829 12:50:13.310716 140460642596672 deprecation.py:506] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0829 12:50:13.324867 140460642596672 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0829 12:50:13.334949 140460642596672 deprecation.py:323] From /home/mindy/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 400 samples, validate on 96 samples\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.5178 - acc: 0.6600 - val_loss: 0.5571 - val_acc: 0.7604\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.76042, saving model to ../tuning_data/best_bottleneck_vgg_model_hat.h5\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 0s 181us/step - loss: 0.4906 - acc: 0.7875 - val_loss: 0.5413 - val_acc: 0.7396\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.76042\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 0s 188us/step - loss: 0.3463 - acc: 0.8600 - val_loss: 0.3461 - val_acc: 0.8958\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.76042 to 0.89583, saving model to ../tuning_data/best_bottleneck_vgg_model_hat.h5\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.2700 - acc: 0.9025 - val_loss: 0.9688 - val_acc: 0.7292\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.89583\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 0s 202us/step - loss: 0.3247 - acc: 0.8700 - val_loss: 0.3138 - val_acc: 0.8958\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.89583\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 0s 211us/step - loss: 0.2164 - acc: 0.9100 - val_loss: 0.5717 - val_acc: 0.7708\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.89583\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 0s 213us/step - loss: 0.2349 - acc: 0.9075 - val_loss: 0.7248 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.89583\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 0s 217us/step - loss: 0.1890 - acc: 0.9500 - val_loss: 0.4762 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.89583\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 0s 202us/step - loss: 0.1549 - acc: 0.9400 - val_loss: 0.4671 - val_acc: 0.8854\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.89583\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.0830 - acc: 0.9700 - val_loss: 0.4728 - val_acc: 0.8854\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.89583\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.1115 - acc: 0.9700 - val_loss: 0.4604 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.89583\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 0s 194us/step - loss: 0.0501 - acc: 0.9750 - val_loss: 1.1527 - val_acc: 0.7396\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.89583\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.0415 - acc: 0.9800 - val_loss: 0.6657 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.89583\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 0s 204us/step - loss: 0.0971 - acc: 0.9700 - val_loss: 0.5093 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.89583\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 0s 206us/step - loss: 0.0157 - acc: 0.9975 - val_loss: 0.7636 - val_acc: 0.8229\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.89583\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 0s 214us/step - loss: 0.0447 - acc: 0.9850 - val_loss: 0.6313 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.89583\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 0s 205us/step - loss: 0.0062 - acc: 0.9975 - val_loss: 0.7113 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.89583\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 0s 191us/step - loss: 0.0160 - acc: 0.9950 - val_loss: 0.7822 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.89583\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 0s 196us/step - loss: 0.0205 - acc: 0.9875 - val_loss: 0.7813 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.89583\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 0s 193us/step - loss: 0.0180 - acc: 0.9900 - val_loss: 0.8830 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.89583\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 0s 193us/step - loss: 0.0802 - acc: 0.9725 - val_loss: 0.8106 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.89583\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 0s 192us/step - loss: 0.0068 - acc: 0.9950 - val_loss: 0.8548 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.89583\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 0s 190us/step - loss: 0.0165 - acc: 0.9975 - val_loss: 0.8626 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.89583\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 0s 194us/step - loss: 0.0688 - acc: 0.9825 - val_loss: 0.8874 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.89583\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 0s 192us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.8819 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.89583\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 0s 199us/step - loss: 0.0138 - acc: 0.9950 - val_loss: 0.8496 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.89583\n",
      "Epoch 27/50\n",
      "400/400 [==============================] - 0s 187us/step - loss: 0.0132 - acc: 0.9925 - val_loss: 0.8851 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.89583\n",
      "Epoch 28/50\n",
      "400/400 [==============================] - 0s 196us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.9495 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.89583\n",
      "Epoch 29/50\n",
      "400/400 [==============================] - 0s 192us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.9645 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.89583\n",
      "Epoch 30/50\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.0142 - acc: 0.9925 - val_loss: 0.9525 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.89583\n",
      "Epoch 31/50\n",
      "400/400 [==============================] - 0s 191us/step - loss: 0.0260 - acc: 0.9900 - val_loss: 1.0000 - val_acc: 0.8229\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.89583\n",
      "Epoch 32/50\n",
      "400/400 [==============================] - 0s 201us/step - loss: 5.7713e-04 - acc: 1.0000 - val_loss: 1.0458 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.89583\n",
      "Epoch 33/50\n",
      "400/400 [==============================] - 0s 196us/step - loss: 0.0276 - acc: 0.9925 - val_loss: 1.0135 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.89583\n",
      "Epoch 34/50\n",
      "400/400 [==============================] - 0s 195us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 1.0873 - val_acc: 0.8229\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.89583\n",
      "Epoch 35/50\n",
      "400/400 [==============================] - 0s 184us/step - loss: 0.0044 - acc: 0.9975 - val_loss: 1.1965 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.89583\n",
      "Epoch 36/50\n",
      "400/400 [==============================] - 0s 200us/step - loss: 0.0247 - acc: 0.9875 - val_loss: 1.1760 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.89583\n",
      "Epoch 37/50\n",
      "400/400 [==============================] - 0s 198us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 1.1635 - val_acc: 0.8229\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.89583\n",
      "Epoch 38/50\n",
      "400/400 [==============================] - 0s 197us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.1068 - val_acc: 0.8125\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.89583\n",
      "Epoch 39/50\n",
      "400/400 [==============================] - 0s 191us/step - loss: 5.6738e-04 - acc: 1.0000 - val_loss: 1.2384 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.89583\n",
      "Epoch 40/50\n",
      "400/400 [==============================] - 0s 198us/step - loss: 0.0034 - acc: 0.9975 - val_loss: 1.1927 - val_acc: 0.8229\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.89583\n",
      "Epoch 41/50\n",
      "400/400 [==============================] - 0s 194us/step - loss: 9.3295e-05 - acc: 1.0000 - val_loss: 1.2905 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.89583\n",
      "Epoch 42/50\n",
      "400/400 [==============================] - 0s 201us/step - loss: 0.0461 - acc: 0.9850 - val_loss: 1.3832 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.89583\n",
      "Epoch 43/50\n",
      "400/400 [==============================] - 0s 207us/step - loss: 0.0023 - acc: 0.9975 - val_loss: 1.3291 - val_acc: 0.8125\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.89583\n",
      "Epoch 44/50\n",
      "400/400 [==============================] - 0s 201us/step - loss: 4.9307e-04 - acc: 1.0000 - val_loss: 1.2603 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.89583\n",
      "Epoch 45/50\n",
      "400/400 [==============================] - 0s 207us/step - loss: 7.7928e-05 - acc: 1.0000 - val_loss: 1.2727 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.89583\n",
      "Epoch 46/50\n",
      "400/400 [==============================] - 0s 190us/step - loss: 7.4260e-06 - acc: 1.0000 - val_loss: 1.2853 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.89583\n",
      "Epoch 47/50\n",
      "400/400 [==============================] - 0s 195us/step - loss: 2.3657e-04 - acc: 1.0000 - val_loss: 1.4924 - val_acc: 0.8125\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.89583\n",
      "Epoch 48/50\n",
      "400/400 [==============================] - 0s 191us/step - loss: 0.0065 - acc: 0.9975 - val_loss: 1.4027 - val_acc: 0.8229\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.89583\n",
      "Epoch 49/50\n",
      "400/400 [==============================] - 0s 191us/step - loss: 5.6997e-04 - acc: 1.0000 - val_loss: 1.3721 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.89583\n",
      "Epoch 50/50\n",
      "400/400 [==============================] - 0s 191us/step - loss: 1.2182e-05 - acc: 1.0000 - val_loss: 1.3709 - val_acc: 0.8229\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.89583\n"
     ]
    }
   ],
   "source": [
    "train_top_model(train_df, test_df, 50, 16, 'hat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tune Top Model to improve accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_model(train_df, test_df,epoch, batch_size,label, print_model = True):\n",
    "    # build VGG16 model and freeze top layers\n",
    "    # input_shape: width, height, RGB (from image generator)\n",
    "    model_vgg = VGG16(weights='imagenet',include_top=False, input_shape=(150,150,3))\n",
    "    # build top model\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=model_vgg.output_shape[1:]))\n",
    "    top_model.add(Dense(256,activation='relu'))\n",
    "    top_model.add(Dropout(0.5))\n",
    "    top_model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # load saved weights to fine tune parameters \n",
    "    top_model.load_weights('../tuning_data/best_bottleneck_vgg_model_hat.h5')\n",
    "    # add top model to model\n",
    "    model = Model(inputs=model_vgg.input, outputs=top_model(model_vgg.output))\n",
    "    # we will tune last 5 layers of the model: block5 and fully connected layer \n",
    "    for layer in model.layers[:15]:\n",
    "        layer.trainable = False\n",
    "    # we can tune the parameters for lr and momentum later to get better results\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "             optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "             metrics=['accuracy'])\n",
    "    # prepare train generator using data augmentation to battle small sample size \n",
    "    train_gen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        shear_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "    # not want to augment the test \n",
    "    test_gen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    train_generator =  train_gen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory='../data/pics',\n",
    "    x_col='pic_id',\n",
    "    y_col=label,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(150,150),\n",
    "    class_mode = 'binary')\n",
    "    \n",
    "    test_generator =  test_gen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory='../data/pics',\n",
    "    x_col='pic_id',\n",
    "    y_col=label,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(150,150),\n",
    "    class_mode = 'binary')\n",
    "    \n",
    "    # checkpoint for best weights \n",
    "    filepath=\"../tuning_data/best_vgg_model_hat.h5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    \n",
    "    # run and fit model \n",
    "    result = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_df.shape[0]//batch_size,\n",
    "    epochs=epoch,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_df.shape[0]//batch_size,\n",
    "    verbose=1, callbacks=callbacks_list)\n",
    "    \n",
    "    # model.save_weights('../tuning_data/vgg16_model_hat.h5')\n",
    "    \n",
    "    if print_model:\n",
    "        model.summary()\n",
    "    del model\n",
    "    keras.backend.clear_session()    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save model history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 408 validated image filenames belonging to 2 classes.\n",
      "Found 102 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "25/25 [==============================] - 3s 128ms/step - loss: 1.8946 - acc: 0.2350 - val_loss: 0.7968 - val_acc: 0.3646\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.36458, saving model to ../tuning_data/best_vgg_model_hat.h5\n",
      "Epoch 2/50\n",
      "25/25 [==============================] - 3s 140ms/step - loss: 0.7555 - acc: 0.4777 - val_loss: 0.7257 - val_acc: 0.3605\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.36458\n",
      "Epoch 3/50\n",
      "25/25 [==============================] - 3s 127ms/step - loss: 0.7289 - acc: 0.4350 - val_loss: 0.7108 - val_acc: 0.4302\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.36458 to 0.43023, saving model to ../tuning_data/best_vgg_model_hat.h5\n",
      "Epoch 4/50\n",
      "25/25 [==============================] - 3s 129ms/step - loss: 0.7045 - acc: 0.5077 - val_loss: 0.7020 - val_acc: 0.4651\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.43023 to 0.46512, saving model to ../tuning_data/best_vgg_model_hat.h5\n",
      "Epoch 5/50\n",
      "25/25 [==============================] - 3s 116ms/step - loss: 0.7221 - acc: 0.4577 - val_loss: 0.6886 - val_acc: 0.5698\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.46512 to 0.56977, saving model to ../tuning_data/best_vgg_model_hat.h5\n",
      "Epoch 6/50\n",
      "25/25 [==============================] - 3s 120ms/step - loss: 0.6763 - acc: 0.5750 - val_loss: 0.6832 - val_acc: 0.5581\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.56977\n",
      "Epoch 7/50\n",
      "25/25 [==============================] - 3s 115ms/step - loss: 0.6848 - acc: 0.5404 - val_loss: 0.6798 - val_acc: 0.5698\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.56977\n",
      "Epoch 8/50\n",
      "25/25 [==============================] - 3s 119ms/step - loss: 0.6690 - acc: 0.5850 - val_loss: 0.6678 - val_acc: 0.6042\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.56977 to 0.60417, saving model to ../tuning_data/best_vgg_model_hat.h5\n",
      "Epoch 9/50\n",
      "25/25 [==============================] - 3s 131ms/step - loss: 0.6593 - acc: 0.5925 - val_loss: 0.6633 - val_acc: 0.6279\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.60417 to 0.62791, saving model to ../tuning_data/best_vgg_model_hat.h5\n",
      "Epoch 10/50\n",
      "25/25 [==============================] - 3s 125ms/step - loss: 0.6456 - acc: 0.6600 - val_loss: 0.6600 - val_acc: 0.5930\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.62791\n",
      "Epoch 11/50\n",
      "25/25 [==============================] - 3s 106ms/step - loss: 0.6278 - acc: 0.6725 - val_loss: 0.6143 - val_acc: 0.7093\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.62791 to 0.70930, saving model to ../tuning_data/best_vgg_model_hat.h5\n",
      "Epoch 12/50\n",
      "25/25 [==============================] - 3s 111ms/step - loss: 0.6177 - acc: 0.7053 - val_loss: 0.6131 - val_acc: 0.6977\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.70930\n",
      "Epoch 13/50\n",
      "25/25 [==============================] - 3s 125ms/step - loss: 0.5990 - acc: 0.7150 - val_loss: 0.6113 - val_acc: 0.6628\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.70930\n",
      "Epoch 14/50\n",
      "25/25 [==============================] - 3s 121ms/step - loss: 0.5657 - acc: 0.7551 - val_loss: 0.5734 - val_acc: 0.7907\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.70930 to 0.79070, saving model to ../tuning_data/best_vgg_model_hat.h5\n",
      "Epoch 15/50\n",
      "25/25 [==============================] - 3s 119ms/step - loss: 0.5303 - acc: 0.7677 - val_loss: 0.5594 - val_acc: 0.7604\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.79070\n",
      "Epoch 16/50\n",
      "25/25 [==============================] - 3s 136ms/step - loss: 0.5241 - acc: 0.7625 - val_loss: 0.4990 - val_acc: 0.8140\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.79070 to 0.81395, saving model to ../tuning_data/best_vgg_model_hat.h5\n",
      "Epoch 17/50\n",
      "25/25 [==============================] - 3s 113ms/step - loss: 0.4904 - acc: 0.7750 - val_loss: 0.5179 - val_acc: 0.7209\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.81395\n",
      "Epoch 18/50\n",
      "25/25 [==============================] - 3s 123ms/step - loss: 0.4472 - acc: 0.8276 - val_loss: 0.5050 - val_acc: 0.7558\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.81395\n",
      "Epoch 19/50\n",
      "25/25 [==============================] - 3s 111ms/step - loss: 0.4340 - acc: 0.8350 - val_loss: 0.4111 - val_acc: 0.7791\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.81395\n",
      "Epoch 20/50\n",
      "25/25 [==============================] - 3s 115ms/step - loss: 0.4261 - acc: 0.8375 - val_loss: 0.4249 - val_acc: 0.8488\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.81395 to 0.84884, saving model to ../tuning_data/best_vgg_model_hat.h5\n",
      "Epoch 21/50\n",
      "25/25 [==============================] - 3s 114ms/step - loss: 0.3869 - acc: 0.8275 - val_loss: 0.3907 - val_acc: 0.8721\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.84884 to 0.87209, saving model to ../tuning_data/best_vgg_model_hat.h5\n",
      "Epoch 22/50\n",
      "25/25 [==============================] - 3s 113ms/step - loss: 0.3585 - acc: 0.8849 - val_loss: 0.3416 - val_acc: 0.8854\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.87209 to 0.88542, saving model to ../tuning_data/best_vgg_model_hat.h5\n",
      "Epoch 23/50\n",
      "25/25 [==============================] - 4s 151ms/step - loss: 0.3583 - acc: 0.8825 - val_loss: 0.4179 - val_acc: 0.8256\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.88542\n",
      "Epoch 24/50\n",
      "25/25 [==============================] - 3s 105ms/step - loss: 0.3392 - acc: 0.8550 - val_loss: 0.3393 - val_acc: 0.8605\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.88542\n",
      "Epoch 25/50\n",
      "25/25 [==============================] - 3s 116ms/step - loss: 0.3329 - acc: 0.8751 - val_loss: 0.3240 - val_acc: 0.8721\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.88542\n",
      "Epoch 26/50\n",
      "25/25 [==============================] - 3s 117ms/step - loss: 0.3079 - acc: 0.8800 - val_loss: 0.2955 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.88542 to 0.90698, saving model to ../tuning_data/best_vgg_model_hat.h5\n",
      "Epoch 27/50\n",
      "25/25 [==============================] - 3s 121ms/step - loss: 0.3132 - acc: 0.8750 - val_loss: 0.2348 - val_acc: 0.9302\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.90698 to 0.93023, saving model to ../tuning_data/best_vgg_model_hat.h5\n",
      "Epoch 28/50\n",
      "25/25 [==============================] - 3s 116ms/step - loss: 0.2874 - acc: 0.8924 - val_loss: 0.3155 - val_acc: 0.8605\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.93023\n",
      "Epoch 29/50\n",
      "25/25 [==============================] - 3s 123ms/step - loss: 0.2884 - acc: 0.8851 - val_loss: 0.2944 - val_acc: 0.9062\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.93023\n",
      "Epoch 30/50\n",
      "25/25 [==============================] - 3s 138ms/step - loss: 0.2735 - acc: 0.9049 - val_loss: 0.2513 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.93023\n",
      "Epoch 31/50\n",
      "25/25 [==============================] - 3s 130ms/step - loss: 0.2394 - acc: 0.9174 - val_loss: 0.2856 - val_acc: 0.8721\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.93023\n",
      "Epoch 32/50\n",
      "25/25 [==============================] - 3s 129ms/step - loss: 0.2694 - acc: 0.9025 - val_loss: 0.2062 - val_acc: 0.9535\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.93023 to 0.95349, saving model to ../tuning_data/best_vgg_model_hat.h5\n",
      "Epoch 33/50\n",
      "25/25 [==============================] - 3s 111ms/step - loss: 0.2309 - acc: 0.9050 - val_loss: 0.2381 - val_acc: 0.9302\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.95349\n",
      "Epoch 34/50\n",
      "25/25 [==============================] - 3s 115ms/step - loss: 0.3061 - acc: 0.8701 - val_loss: 0.2758 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.95349\n",
      "Epoch 35/50\n",
      "25/25 [==============================] - 3s 124ms/step - loss: 0.2364 - acc: 0.9100 - val_loss: 0.2675 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.95349\n",
      "Epoch 36/50\n",
      "25/25 [==============================] - 3s 116ms/step - loss: 0.2129 - acc: 0.9224 - val_loss: 0.2208 - val_acc: 0.9271\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.95349\n",
      "Epoch 37/50\n",
      "25/25 [==============================] - 3s 135ms/step - loss: 0.2153 - acc: 0.9325 - val_loss: 0.2308 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.95349\n",
      "Epoch 38/50\n",
      "25/25 [==============================] - 3s 115ms/step - loss: 0.2230 - acc: 0.9125 - val_loss: 0.2298 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.95349\n",
      "Epoch 39/50\n",
      "25/25 [==============================] - 3s 129ms/step - loss: 0.2095 - acc: 0.9226 - val_loss: 0.2621 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.95349\n",
      "Epoch 40/50\n",
      "25/25 [==============================] - 3s 108ms/step - loss: 0.2128 - acc: 0.9349 - val_loss: 0.1973 - val_acc: 0.9302\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.95349\n",
      "Epoch 41/50\n",
      "25/25 [==============================] - 3s 114ms/step - loss: 0.1717 - acc: 0.9450 - val_loss: 0.1928 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.95349\n",
      "Epoch 42/50\n",
      "25/25 [==============================] - 3s 118ms/step - loss: 0.2160 - acc: 0.9251 - val_loss: 0.2039 - val_acc: 0.9302\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.95349\n",
      "Epoch 43/50\n",
      "25/25 [==============================] - 3s 125ms/step - loss: 0.2046 - acc: 0.9349 - val_loss: 0.3146 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.95349\n",
      "Epoch 44/50\n",
      "25/25 [==============================] - 3s 133ms/step - loss: 0.1974 - acc: 0.9350 - val_loss: 0.2320 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.95349\n",
      "Epoch 45/50\n",
      "25/25 [==============================] - 3s 110ms/step - loss: 0.1748 - acc: 0.9377 - val_loss: 0.1679 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.95349\n",
      "Epoch 46/50\n",
      "25/25 [==============================] - 3s 130ms/step - loss: 0.1924 - acc: 0.9375 - val_loss: 0.2329 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.95349\n",
      "Epoch 47/50\n",
      "25/25 [==============================] - 3s 117ms/step - loss: 0.1628 - acc: 0.9450 - val_loss: 0.1918 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.95349\n",
      "Epoch 48/50\n",
      "25/25 [==============================] - 3s 109ms/step - loss: 0.1993 - acc: 0.9300 - val_loss: 0.1648 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.95349\n",
      "Epoch 49/50\n",
      "25/25 [==============================] - 3s 121ms/step - loss: 0.1449 - acc: 0.9500 - val_loss: 0.2307 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.95349\n",
      "Epoch 50/50\n",
      "25/25 [==============================] - 3s 128ms/step - loss: 0.1392 - acc: 0.9551 - val_loss: 0.1820 - val_acc: 0.9271\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.95349\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 2097665   \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 9,177,089\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_history = fine_tune_model(train_df, test_df,50,16,'hat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest test accuracy: 0.9534883720930233\n",
      "------------------\n",
      "highest train accuracy: 0.9566326530612245\n"
     ]
    }
   ],
   "source": [
    "highest_val_acc, highest_train_acc = max(model_history.history['val_acc']), max(model_history.history['acc'])\n",
    "print(f'highest test accuracy: {highest_val_acc}')\n",
    "print('------------------')\n",
    "print(f'highest train accuracy: {highest_train_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowest test loss: 0.16477232824924382\n",
      "------------------\n",
      "lowest train loss: 0.13535378827732436\n"
     ]
    }
   ],
   "source": [
    "lowest_val_loss, lowest_train_loss = min(model_history.history['val_loss']), min(model_history.history['loss'])\n",
    "print(f'lowest test loss: {lowest_val_loss}')\n",
    "print('------------------')\n",
    "print(f'lowest train loss: {lowest_train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_history.history['val_acc'], color = 'red', label = 'test')\n",
    "plt.plot(model_history.history['acc'], color = 'blue', label = 'train')\n",
    "plt.title('accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_history.history['val_loss'], color = 'red', label = 'test')\n",
    "plt.plot(model_history.history['loss'], color = 'blue', label = 'train')\n",
    "plt.title('loss')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model artchitecture \n",
    "hat_model = model_history.model\n",
    "hat_model_json = hat_model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "with open(\"hat_model.json\", \"w\") as json_file:\n",
    "    json_file.write(hat_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open('hat_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model_hat = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model weight \n",
    "loaded_model_hat.load_weights('../tuning_data/best_vgg_model_hat.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 102 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator =  test_gen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory='../data/pics',\n",
    "    x_col='pic_id',\n",
    "    y_col='hat',\n",
    "    batch_size=16,\n",
    "    target_size=(150,150),\n",
    "    class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_hat.compile(loss='binary_crossentropy',\n",
    "             optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.24847973737062193, 0.9215686274509803]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model_hat.evaluate_generator(test_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
