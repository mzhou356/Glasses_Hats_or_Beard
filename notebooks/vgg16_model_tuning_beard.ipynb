{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning Tuning_beard:\n",
    "  * model parameter and other information can be found below:\n",
    "     * [source](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)\n",
    "     \n",
    "  * base_model: use vgg16 and freeze at bottleneck layer (stop right before flatten layer) \n",
    "  * top_model: tune dense layers (parameters are inspired by source)\n",
    "     * batch_size 16 seems to work best for small data set \n",
    "\n",
    "##### warnings: make sure to restart kernel in between running different model tuning \n",
    "  \n",
    "---\n",
    "#### This cell is required in order to use GPU for running the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0829 13:30:32.548914 140667119040320 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0829 13:30:32.549813 140667119040320 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "                                    # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
    "keras.backend.get_session().run(tf.global_variables_initializer())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import optimizers\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Import train_df and test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('../pickle_files/train_df_beard.pkl')\n",
    "test_df = pd.read_pickle('../pickle_files/test_df_beard.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get bottleneck features to tune top models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_bottleneck_features(train_df, test_df, label, batch_size):\n",
    "    '''\n",
    "    inputs:\n",
    "    train_df, test_df: train and test dataframes saved in pickle_files folder\n",
    "    label: a string, eyewear, hat, or beard\n",
    "    batch_size: process images in batches\n",
    "    outputs:\n",
    "    saves bottleneck features inside folder tuning_data as npy file\n",
    "    '''\n",
    "    # intialize the vgg16 model \n",
    "    # make sure not to train the top layers \n",
    "    base_model = VGG16(weights = 'imagenet', include_top = False)\n",
    "    # create train_generator and test_generator to get bottleneck inputs for train and test df \n",
    "    datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "    # make sure shuffle is False so we know the label follows the sequence of the dataframe \n",
    "    # so we can tune top_model \n",
    "    train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory='../data/pics',\n",
    "    x_col='pic_id',\n",
    "    y_col=label,\n",
    "    batch_size=batch_size,\n",
    "    shuffle = False,\n",
    "    target_size=(150,150),\n",
    "    class_mode = None)\n",
    "    # get features saved as .npy in tunign_data folder \n",
    "    bottleneck_features_train = base_model.predict_generator(\n",
    "        train_generator, train_df.shape[0]//batch_size)\n",
    "    np.save(open('../tuning_data/bottleneck_features_train_beard.npy','wb'),\n",
    "           bottleneck_features_train)\n",
    "    \n",
    "    test_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory='../data/pics',\n",
    "    x_col='pic_id',\n",
    "    y_col=label,\n",
    "    batch_size=batch_size,\n",
    "    shuffle = False,\n",
    "    target_size=(150,150),\n",
    "    class_mode = None)\n",
    "    bottleneck_features_test = base_model.predict_generator(\n",
    "        test_generator, test_df.shape[0]//batch_size)\n",
    "    np.save(open('../tuning_data/bottleneck_features_test_beard.npy','wb'),\n",
    "           bottleneck_features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save bottleneck_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0829 13:31:41.025565 140667119040320 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0829 13:31:41.026250 140667119040320 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0829 13:31:41.028058 140667119040320 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0829 13:31:41.043291 140667119040320 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 363 validated image filenames.\n",
      "Found 91 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "save_bottleneck_features(train_df,test_df,'beard',16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick tuning of top models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_top_model(train_df, test_df, epoch, batch_size, label):\n",
    "    '''\n",
    "    inputs:\n",
    "    train_df, test_df: dataframes saved in pickle_files to generate train and test labels \n",
    "    epoch: num of epochs in fit \n",
    "    batch_size: same as image generator batch size \n",
    "    label: a string, eyewear, hat, or beard\n",
    "    output:\n",
    "    saves model weights in a folder \n",
    "    '''\n",
    "    train_data = np.load(open('../tuning_data/bottleneck_features_train_beard.npy','rb'))\n",
    "    # make sure train_data and train_label have same num of samples\n",
    "    train_label = np.array(train_df[label].map({'not_'+label:0, label:1}))[:-(train_df.shape[0]%batch_size)]\n",
    "    \n",
    "    test_data = np.load(open('../tuning_data/bottleneck_features_test_beard.npy','rb'))\n",
    "    test_label = np.array(test_df[label].map({'not_'+label:0, label:1}))[:-(test_df.shape[0]%batch_size)]\n",
    "    \n",
    "    # build top model\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='rmsprop',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "     # checkpoint for best weights \n",
    "    filepath=\"../tuning_data/best_bottleneck_vgg_model_beard.h5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    \n",
    "    model.fit(train_data, train_label,\n",
    "             epochs=epoch,\n",
    "             batch_size=batch_size,\n",
    "             validation_data=(test_data,test_label),\n",
    "             callbacks=callbacks_list)\n",
    "    del model\n",
    "    keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run train_top_model and save results in tuning_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0829 13:33:32.124638 140667119040320 deprecation.py:506] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0829 13:33:32.136728 140667119040320 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0829 13:33:32.147027 140667119040320 deprecation.py:323] From /home/mindy/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 352 samples, validate on 80 samples\n",
      "Epoch 1/50\n",
      "352/352 [==============================] - 0s 1ms/step - loss: 2.2591 - acc: 0.5625 - val_loss: 0.5306 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.80000, saving model to ../tuning_data/best_bottleneck_vgg_model_beard.h5\n",
      "Epoch 2/50\n",
      "352/352 [==============================] - 0s 191us/step - loss: 0.6313 - acc: 0.7699 - val_loss: 1.0175 - val_acc: 0.5875\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.80000\n",
      "Epoch 3/50\n",
      "352/352 [==============================] - 0s 189us/step - loss: 0.3825 - acc: 0.8267 - val_loss: 0.6781 - val_acc: 0.7750\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.80000\n",
      "Epoch 4/50\n",
      "352/352 [==============================] - 0s 193us/step - loss: 0.5254 - acc: 0.8125 - val_loss: 0.6865 - val_acc: 0.7750\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.80000\n",
      "Epoch 5/50\n",
      "352/352 [==============================] - 0s 194us/step - loss: 0.3343 - acc: 0.8750 - val_loss: 0.7847 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.80000\n",
      "Epoch 6/50\n",
      "352/352 [==============================] - 0s 189us/step - loss: 0.2911 - acc: 0.8835 - val_loss: 0.3125 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.80000 to 0.87500, saving model to ../tuning_data/best_bottleneck_vgg_model_beard.h5\n",
      "Epoch 7/50\n",
      "352/352 [==============================] - 0s 190us/step - loss: 0.3289 - acc: 0.8892 - val_loss: 0.3081 - val_acc: 0.8500\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.87500\n",
      "Epoch 8/50\n",
      "352/352 [==============================] - 0s 198us/step - loss: 0.0929 - acc: 0.9631 - val_loss: 0.7980 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.87500\n",
      "Epoch 9/50\n",
      "352/352 [==============================] - 0s 195us/step - loss: 0.2171 - acc: 0.9176 - val_loss: 0.4619 - val_acc: 0.8500\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.87500\n",
      "Epoch 10/50\n",
      "352/352 [==============================] - 0s 205us/step - loss: 0.0738 - acc: 0.9744 - val_loss: 0.6214 - val_acc: 0.8250\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.87500\n",
      "Epoch 11/50\n",
      "352/352 [==============================] - 0s 203us/step - loss: 0.1436 - acc: 0.9290 - val_loss: 0.4095 - val_acc: 0.9000\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.87500 to 0.90000, saving model to ../tuning_data/best_bottleneck_vgg_model_beard.h5\n",
      "Epoch 12/50\n",
      "352/352 [==============================] - 0s 211us/step - loss: 0.1312 - acc: 0.9602 - val_loss: 1.0237 - val_acc: 0.7625\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.90000\n",
      "Epoch 13/50\n",
      "352/352 [==============================] - 0s 204us/step - loss: 0.0499 - acc: 0.9830 - val_loss: 1.4259 - val_acc: 0.7125\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.90000\n",
      "Epoch 14/50\n",
      "352/352 [==============================] - 0s 189us/step - loss: 0.0214 - acc: 0.9943 - val_loss: 0.4820 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.90000\n",
      "Epoch 15/50\n",
      "352/352 [==============================] - 0s 191us/step - loss: 0.1409 - acc: 0.9517 - val_loss: 0.4612 - val_acc: 0.8500\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.90000\n",
      "Epoch 16/50\n",
      "352/352 [==============================] - 0s 189us/step - loss: 0.0761 - acc: 0.9744 - val_loss: 0.4405 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.90000\n",
      "Epoch 17/50\n",
      "352/352 [==============================] - 0s 186us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.4230 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.90000\n",
      "Epoch 18/50\n",
      "352/352 [==============================] - 0s 183us/step - loss: 0.1429 - acc: 0.9716 - val_loss: 0.6044 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.90000\n",
      "Epoch 19/50\n",
      "352/352 [==============================] - 0s 196us/step - loss: 0.0168 - acc: 0.9943 - val_loss: 0.5003 - val_acc: 0.9000\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.90000\n",
      "Epoch 20/50\n",
      "352/352 [==============================] - 0s 189us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.6728 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.90000\n",
      "Epoch 21/50\n",
      "352/352 [==============================] - 0s 197us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.9096 - val_acc: 0.8375\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.90000\n",
      "Epoch 22/50\n",
      "352/352 [==============================] - 0s 195us/step - loss: 0.0956 - acc: 0.9631 - val_loss: 0.6442 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.90000\n",
      "Epoch 23/50\n",
      "352/352 [==============================] - 0s 191us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.7986 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.90000\n",
      "Epoch 24/50\n",
      "352/352 [==============================] - 0s 189us/step - loss: 0.0146 - acc: 0.9943 - val_loss: 0.6948 - val_acc: 0.8375\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.90000\n",
      "Epoch 25/50\n",
      "352/352 [==============================] - 0s 189us/step - loss: 0.0233 - acc: 0.9943 - val_loss: 1.3821 - val_acc: 0.7750\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.90000\n",
      "Epoch 26/50\n",
      "352/352 [==============================] - 0s 185us/step - loss: 0.0120 - acc: 0.9943 - val_loss: 0.8244 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.90000\n",
      "Epoch 27/50\n",
      "352/352 [==============================] - 0s 188us/step - loss: 0.0132 - acc: 0.9915 - val_loss: 0.6683 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.90000\n",
      "Epoch 28/50\n",
      "352/352 [==============================] - 0s 189us/step - loss: 0.0601 - acc: 0.9744 - val_loss: 0.7610 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.90000\n",
      "Epoch 29/50\n",
      "352/352 [==============================] - 0s 195us/step - loss: 0.0132 - acc: 0.9943 - val_loss: 0.9476 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.90000\n",
      "Epoch 30/50\n",
      "352/352 [==============================] - 0s 185us/step - loss: 5.9567e-04 - acc: 1.0000 - val_loss: 0.8663 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.90000\n",
      "Epoch 31/50\n",
      "352/352 [==============================] - 0s 186us/step - loss: 2.0097e-04 - acc: 1.0000 - val_loss: 0.9479 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.90000\n",
      "Epoch 32/50\n",
      "352/352 [==============================] - 0s 188us/step - loss: 0.0758 - acc: 0.9801 - val_loss: 0.9348 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.90000\n",
      "Epoch 33/50\n",
      "352/352 [==============================] - 0s 185us/step - loss: 0.0145 - acc: 0.9972 - val_loss: 0.7466 - val_acc: 0.8500\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.90000\n",
      "Epoch 34/50\n",
      "352/352 [==============================] - 0s 196us/step - loss: 0.0064 - acc: 0.9972 - val_loss: 0.8058 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.90000\n",
      "Epoch 35/50\n",
      "352/352 [==============================] - 0s 192us/step - loss: 0.0462 - acc: 0.9858 - val_loss: 0.8157 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.90000\n",
      "Epoch 36/50\n",
      "352/352 [==============================] - 0s 188us/step - loss: 3.3269e-04 - acc: 1.0000 - val_loss: 0.8305 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.90000\n",
      "Epoch 37/50\n",
      "352/352 [==============================] - 0s 196us/step - loss: 6.8131e-04 - acc: 1.0000 - val_loss: 1.1436 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.90000\n",
      "Epoch 38/50\n",
      "352/352 [==============================] - 0s 192us/step - loss: 0.0345 - acc: 0.9915 - val_loss: 0.7251 - val_acc: 0.9000\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.90000\n",
      "Epoch 39/50\n",
      "352/352 [==============================] - 0s 187us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.9645 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.90000 to 0.91250, saving model to ../tuning_data/best_bottleneck_vgg_model_beard.h5\n",
      "Epoch 40/50\n",
      "352/352 [==============================] - 0s 185us/step - loss: 4.7484e-04 - acc: 1.0000 - val_loss: 0.7473 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.91250\n",
      "Epoch 41/50\n",
      "352/352 [==============================] - 0s 186us/step - loss: 0.0140 - acc: 0.9915 - val_loss: 0.7666 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.91250\n",
      "Epoch 42/50\n",
      "352/352 [==============================] - 0s 187us/step - loss: 0.0047 - acc: 0.9972 - val_loss: 0.7681 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.91250\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 0s 186us/step - loss: 6.2418e-04 - acc: 1.0000 - val_loss: 0.8473 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.91250\n",
      "Epoch 44/50\n",
      "352/352 [==============================] - 0s 194us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.1180 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.91250\n",
      "Epoch 45/50\n",
      "352/352 [==============================] - 0s 191us/step - loss: 1.3537e-04 - acc: 1.0000 - val_loss: 1.1606 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.91250\n",
      "Epoch 46/50\n",
      "352/352 [==============================] - 0s 189us/step - loss: 5.5047e-04 - acc: 1.0000 - val_loss: 0.9638 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.91250\n",
      "Epoch 47/50\n",
      "352/352 [==============================] - 0s 189us/step - loss: 0.0224 - acc: 0.9943 - val_loss: 0.9294 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.91250\n",
      "Epoch 48/50\n",
      "352/352 [==============================] - 0s 193us/step - loss: 0.0119 - acc: 0.9972 - val_loss: 0.8750 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.91250\n",
      "Epoch 49/50\n",
      "352/352 [==============================] - 0s 199us/step - loss: 8.2390e-05 - acc: 1.0000 - val_loss: 0.9607 - val_acc: 0.9000\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.91250\n",
      "Epoch 50/50\n",
      "352/352 [==============================] - 0s 192us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.9594 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.91250\n"
     ]
    }
   ],
   "source": [
    "train_top_model(train_df, test_df, 50, 16, 'beard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tune Top Model to improve accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_model(train_df, test_df,epoch, batch_size,label, print_model = True):\n",
    "    # build VGG16 model and freeze top layers\n",
    "    # input_shape: width, height, RGB (from image generator)\n",
    "    model_vgg = VGG16(weights='imagenet',include_top=False, input_shape=(150,150,3))\n",
    "    # build top model\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=model_vgg.output_shape[1:]))\n",
    "    top_model.add(Dense(256,activation='relu'))\n",
    "    top_model.add(Dropout(0.5))\n",
    "    top_model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # load saved weights to fine tune parameters \n",
    "    top_model.load_weights('../tuning_data/best_bottleneck_vgg_model_beard.h5')\n",
    "    # add top model to model\n",
    "    model = Model(inputs=model_vgg.input, outputs=top_model(model_vgg.output))\n",
    "    # we will tune last 5 layers of the model: block5 and fully connected layer \n",
    "    for layer in model.layers[:15]:\n",
    "        layer.trainable = False\n",
    "    # we can tune the parameters for lr and momentum later to get better results\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "             optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "             metrics=['accuracy'])\n",
    "    # prepare train generator using data augmentation to battle small sample size \n",
    "    train_gen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "    # not want to augment the test \n",
    "    test_gen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    train_generator =  train_gen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory='../data/pics',\n",
    "    x_col='pic_id',\n",
    "    y_col=label,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(150,150),\n",
    "    class_mode = 'binary')\n",
    "    \n",
    "    test_generator =  test_gen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory='../data/pics',\n",
    "    x_col='pic_id',\n",
    "    y_col=label,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(150,150),\n",
    "    class_mode = 'binary')\n",
    "    \n",
    "    # checkpoint for best weights \n",
    "    filepath=\"../tuning_data/best_vgg_model_beard.h5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    \n",
    "    # run and fit model \n",
    "    result = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_df.shape[0]//batch_size,\n",
    "    epochs=epoch,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_df.shape[0]//batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list)\n",
    "\n",
    "    if print_model:\n",
    "        model.summary()\n",
    "        \n",
    "    del model\n",
    "    keras.backend.clear_session()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save model history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 363 validated image filenames belonging to 2 classes.\n",
      "Found 91 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "22/22 [==============================] - 3s 152ms/step - loss: 4.1282 - acc: 0.3246 - val_loss: 0.6967 - val_acc: 0.5375\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.53750, saving model to ../tuning_data/best_vgg_model_beard.h5\n",
      "Epoch 2/50\n",
      "22/22 [==============================] - 3s 137ms/step - loss: 0.7177 - acc: 0.5427 - val_loss: 0.6312 - val_acc: 0.6933\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.53750 to 0.69333, saving model to ../tuning_data/best_vgg_model_beard.h5\n",
      "Epoch 3/50\n",
      "22/22 [==============================] - 3s 138ms/step - loss: 0.6635 - acc: 0.5873 - val_loss: 0.6622 - val_acc: 0.5733\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.69333\n",
      "Epoch 4/50\n",
      "22/22 [==============================] - 3s 122ms/step - loss: 0.6169 - acc: 0.6410 - val_loss: 0.5871 - val_acc: 0.7467\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.69333 to 0.74667, saving model to ../tuning_data/best_vgg_model_beard.h5\n",
      "Epoch 5/50\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.5155 - acc: 0.7271 - val_loss: 0.4728 - val_acc: 0.7867\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.74667 to 0.78667, saving model to ../tuning_data/best_vgg_model_beard.h5\n",
      "Epoch 6/50\n",
      "22/22 [==============================] - 3s 128ms/step - loss: 0.4958 - acc: 0.7417 - val_loss: 0.4311 - val_acc: 0.8267\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.78667 to 0.82667, saving model to ../tuning_data/best_vgg_model_beard.h5\n",
      "Epoch 7/50\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 0.4599 - acc: 0.8042 - val_loss: 0.4103 - val_acc: 0.8125\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.82667\n",
      "Epoch 8/50\n",
      "22/22 [==============================] - 3s 139ms/step - loss: 0.4231 - acc: 0.8188 - val_loss: 0.3818 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.82667 to 0.86667, saving model to ../tuning_data/best_vgg_model_beard.h5\n",
      "Epoch 9/50\n",
      "22/22 [==============================] - 3s 131ms/step - loss: 0.4252 - acc: 0.8087 - val_loss: 0.3961 - val_acc: 0.8400\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.86667\n",
      "Epoch 10/50\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.4188 - acc: 0.8011 - val_loss: 0.4251 - val_acc: 0.8133\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.86667\n",
      "Epoch 11/50\n",
      "22/22 [==============================] - 3s 139ms/step - loss: 0.3599 - acc: 0.8374 - val_loss: 0.1930 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.86667 to 0.92000, saving model to ../tuning_data/best_vgg_model_beard.h5\n",
      "Epoch 12/50\n",
      "22/22 [==============================] - 3s 117ms/step - loss: 0.3484 - acc: 0.8494 - val_loss: 0.3508 - val_acc: 0.8533\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92000\n",
      "Epoch 13/50\n",
      "22/22 [==============================] - 3s 124ms/step - loss: 0.3156 - acc: 0.8834 - val_loss: 0.3057 - val_acc: 0.8500\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.92000\n",
      "Epoch 14/50\n",
      "22/22 [==============================] - 3s 139ms/step - loss: 0.2983 - acc: 0.8794 - val_loss: 0.2503 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.92000\n",
      "Epoch 15/50\n",
      "22/22 [==============================] - 2s 110ms/step - loss: 0.2718 - acc: 0.8882 - val_loss: 0.3215 - val_acc: 0.8800\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.92000\n",
      "Epoch 16/50\n",
      "22/22 [==============================] - 3s 143ms/step - loss: 0.3133 - acc: 0.8879 - val_loss: 0.2642 - val_acc: 0.8533\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.92000\n",
      "Epoch 17/50\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 0.2691 - acc: 0.9006 - val_loss: 0.2559 - val_acc: 0.8800\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.92000\n",
      "Epoch 18/50\n",
      "22/22 [==============================] - 3s 121ms/step - loss: 0.2756 - acc: 0.8826 - val_loss: 0.3239 - val_acc: 0.8800\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.92000\n",
      "Epoch 19/50\n",
      "22/22 [==============================] - 3s 136ms/step - loss: 0.3089 - acc: 0.8749 - val_loss: 0.2572 - val_acc: 0.9000\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.92000\n",
      "Epoch 20/50\n",
      "22/22 [==============================] - 3s 140ms/step - loss: 0.2110 - acc: 0.9236 - val_loss: 0.2390 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.92000\n",
      "Epoch 21/50\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.2429 - acc: 0.8936 - val_loss: 0.2456 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.92000 to 0.93333, saving model to ../tuning_data/best_vgg_model_beard.h5\n",
      "Epoch 22/50\n",
      "22/22 [==============================] - 3s 127ms/step - loss: 0.2152 - acc: 0.9122 - val_loss: 0.2620 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.93333\n",
      "Epoch 23/50\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 0.1818 - acc: 0.9293 - val_loss: 0.2278 - val_acc: 0.8800\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.93333\n",
      "Epoch 24/50\n",
      "22/22 [==============================] - 3s 125ms/step - loss: 0.1621 - acc: 0.9334 - val_loss: 0.1884 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.93333\n",
      "Epoch 25/50\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 0.1700 - acc: 0.9517 - val_loss: 0.1816 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.93333\n",
      "Epoch 26/50\n",
      "22/22 [==============================] - 3s 143ms/step - loss: 0.1396 - acc: 0.9407 - val_loss: 0.1741 - val_acc: 0.9467\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.93333 to 0.94667, saving model to ../tuning_data/best_vgg_model_beard.h5\n",
      "Epoch 27/50\n",
      "22/22 [==============================] - 3s 132ms/step - loss: 0.1616 - acc: 0.9362 - val_loss: 0.3348 - val_acc: 0.8800\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.94667\n",
      "Epoch 28/50\n",
      "22/22 [==============================] - 3s 120ms/step - loss: 0.1627 - acc: 0.9179 - val_loss: 0.1453 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.94667\n",
      "Epoch 29/50\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.1086 - acc: 0.9801 - val_loss: 0.2372 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.94667\n",
      "Epoch 30/50\n",
      "22/22 [==============================] - 3s 127ms/step - loss: 0.1749 - acc: 0.9290 - val_loss: 0.2487 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.94667\n",
      "Epoch 31/50\n",
      "22/22 [==============================] - 3s 131ms/step - loss: 0.1485 - acc: 0.9492 - val_loss: 0.1911 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.94667\n",
      "Epoch 32/50\n",
      "22/22 [==============================] - 3s 148ms/step - loss: 0.1155 - acc: 0.9574 - val_loss: 0.2406 - val_acc: 0.8533\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.94667\n",
      "Epoch 33/50\n",
      "22/22 [==============================] - 3s 128ms/step - loss: 0.1154 - acc: 0.9602 - val_loss: 0.1721 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.94667\n",
      "Epoch 34/50\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.1142 - acc: 0.9606 - val_loss: 0.1426 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.94667\n",
      "Epoch 35/50\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.1021 - acc: 0.9630 - val_loss: 0.1669 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.94667\n",
      "Epoch 36/50\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.1130 - acc: 0.9602 - val_loss: 0.2006 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.94667\n",
      "Epoch 37/50\n",
      "22/22 [==============================] - 3s 140ms/step - loss: 0.0767 - acc: 0.9874 - val_loss: 0.1997 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.94667\n",
      "Epoch 38/50\n",
      "22/22 [==============================] - 3s 125ms/step - loss: 0.1109 - acc: 0.9602 - val_loss: 0.1868 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.94667\n",
      "Epoch 39/50\n",
      "22/22 [==============================] - 3s 125ms/step - loss: 0.0857 - acc: 0.9773 - val_loss: 0.1466 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.94667\n",
      "Epoch 40/50\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.0672 - acc: 0.9829 - val_loss: 0.1638 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.94667\n",
      "Epoch 41/50\n",
      "22/22 [==============================] - 3s 138ms/step - loss: 0.1055 - acc: 0.9574 - val_loss: 0.3125 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.94667\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 3s 121ms/step - loss: 0.1290 - acc: 0.9508 - val_loss: 0.1583 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.94667\n",
      "Epoch 43/50\n",
      "22/22 [==============================] - 3s 134ms/step - loss: 0.0594 - acc: 0.9886 - val_loss: 0.2060 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.94667\n",
      "Epoch 44/50\n",
      "22/22 [==============================] - 3s 143ms/step - loss: 0.1068 - acc: 0.9545 - val_loss: 0.2118 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.94667\n",
      "Epoch 45/50\n",
      "22/22 [==============================] - 3s 131ms/step - loss: 0.0794 - acc: 0.9744 - val_loss: 0.0706 - val_acc: 0.9600\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.94667 to 0.96000, saving model to ../tuning_data/best_vgg_model_beard.h5\n",
      "Epoch 46/50\n",
      "22/22 [==============================] - 3s 118ms/step - loss: 0.0545 - acc: 0.9829 - val_loss: 0.2557 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.96000\n",
      "Epoch 47/50\n",
      "22/22 [==============================] - 3s 127ms/step - loss: 0.0799 - acc: 0.9829 - val_loss: 0.1357 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.96000\n",
      "Epoch 48/50\n",
      "22/22 [==============================] - 3s 126ms/step - loss: 0.0661 - acc: 0.9846 - val_loss: 0.2189 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.96000\n",
      "Epoch 49/50\n",
      "22/22 [==============================] - 3s 132ms/step - loss: 0.0815 - acc: 0.9789 - val_loss: 0.2028 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.96000\n",
      "Epoch 50/50\n",
      "22/22 [==============================] - 3s 147ms/step - loss: 0.0719 - acc: 0.9817 - val_loss: 0.1259 - val_acc: 0.9600\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.96000\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 2097665   \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 9,177,089\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_history = fine_tune_model(train_df, test_df,50,16,'beard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest test accuracy: 0.9600000039736429\n",
      "------------------\n",
      "highest train accuracy: 0.9886363636363636\n"
     ]
    }
   ],
   "source": [
    "highest_val_acc, highest_train_acc = max(model_history.history['val_acc']), max(model_history.history['acc'])\n",
    "print(f'highest test accuracy: {highest_val_acc}')\n",
    "print('------------------')\n",
    "print(f'highest train accuracy: {highest_train_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowest test loss: 0.07060661147038141\n",
      "------------------\n",
      "lowest train loss: 0.05498526646334259\n"
     ]
    }
   ],
   "source": [
    "lowest_val_loss, lowest_train_loss = min(model_history.history['val_loss']), min(model_history.history['loss'])\n",
    "print(f'lowest test loss: {lowest_val_loss}')\n",
    "print('------------------')\n",
    "print(f'lowest train loss: {lowest_train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_history.history['val_acc'], color = 'red', label = 'test')\n",
    "plt.plot(model_history.history['acc'], color = 'blue', label = 'train')\n",
    "plt.title('accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_history.history['val_loss'], color = 'red', label = 'test')\n",
    "plt.plot(model_history.history['loss'], color = 'blue', label = 'train')\n",
    "plt.title('loss')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model artchitecture \n",
    "beard_model = model_history.model\n",
    "beard_model_json = beard_model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "with open(\"beard_model.json\", \"w\") as json_file:\n",
    "    json_file.write(beard_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open('beard_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model_beard = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model weight \n",
    "loaded_model_beard.load_weights('../tuning_data/best_vgg_model_beard.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 91 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator =  test_gen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory='../data/pics',\n",
    "    x_col='pic_id',\n",
    "    y_col='beard',\n",
    "    batch_size=16,\n",
    "    target_size=(150,150),\n",
    "    class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_beard.compile(loss='binary_crossentropy',\n",
    "             optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.167782618531159, 0.945054945054945]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model_beard.evaluate_generator(test_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
