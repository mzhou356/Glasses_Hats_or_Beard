{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning Tuning_EyeWear:\n",
    "  * model parameter and other information can be found below:\n",
    "     * [source](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)\n",
    "     \n",
    "  * base_model: use vgg16 and freeze at bottleneck layer (stop right before flatten layer) \n",
    "  * top_model: tune dense layers (parameters are inspired by source)\n",
    "     * batch_size 16 seems to work best for small data set \n",
    "     \n",
    "  * extra blog source for callbacks and saving models:\n",
    "  \n",
    "  [call_backs for best weights](https://machinelearningmastery.com/check-point-deep-learning-models-keras/)\n",
    "  \n",
    "  [saving models](https://machinelearningmastery.com/save-load-keras-deep-learning-models/)\n",
    "\n",
    "##### warnings: due to the order of my dataframe, the first entry is not_eyewear, class predict 1 == has no eyewear\n",
    "  \n",
    "---\n",
    "#### This cell is required in order to use GPU for running the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0831 22:13:27.989720 140695323678528 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0831 22:13:27.990682 140695323678528 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "                                    # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
    "keras.backend.get_session().run(tf.global_variables_initializer())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras import optimizers\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Import train_df and test_df for eyewears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('../pickle_files/train_df_glasses.pkl')\n",
    "test_df = pd.read_pickle('../pickle_files/test_df_glasses.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get bottleneck features to tune top models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_bottleneck_features(train_df, test_df, label, batch_size):\n",
    "    '''\n",
    "    inputs:\n",
    "    train_df, test_df: train and test dataframes saved in pickle_files folder\n",
    "    label: a string, eyewear, hat, or beard\n",
    "    batch_size: process images in batches\n",
    "    outputs:\n",
    "    saves bottleneck features inside folder tuning_data as npy file\n",
    "    '''\n",
    "    # intialize the vgg16 model \n",
    "    # make sure not to train the top layers \n",
    "    base_model = VGG16(weights = 'imagenet', include_top = False)\n",
    "    # create train_generator and test_generator to get bottleneck inputs for train and test df \n",
    "    datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        zoom_range= [0.8,1.7],\n",
    "        shear_range=0.2,\n",
    "        rotation_range = 40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        preprocessing_function=preprocess_input) # add reprocess to prevent overfitting \n",
    "    # make sure shuffle is False so we know the label follows the sequence of the dataframe \n",
    "    # so we can tune top_model \n",
    "    train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory='../data/pics',\n",
    "    x_col='pic_id',\n",
    "    y_col=label,\n",
    "    batch_size=batch_size,\n",
    "    shuffle = False,\n",
    "    target_size=(224,224),\n",
    "    class_mode = None)\n",
    "    # get features saved as .npy in tunign_data folder \n",
    "    bottleneck_features_train = base_model.predict_generator(\n",
    "        train_generator, train_df.shape[0]//batch_size)\n",
    "    np.save(open('../tuning_data/bottleneck_features_train_eyewears_3.npy','wb'),\n",
    "           bottleneck_features_train)\n",
    "    \n",
    "    test_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory='../data/pics',\n",
    "    x_col='pic_id',\n",
    "    y_col=label,\n",
    "    batch_size=batch_size,\n",
    "    shuffle = False,\n",
    "    target_size=(224,224),  # change to default input size \n",
    "    class_mode = None)\n",
    "    bottleneck_features_test = base_model.predict_generator(\n",
    "        test_generator, test_df.shape[0]//batch_size)\n",
    "    np.save(open('../tuning_data/bottleneck_features_test_eyewears_3.npy','wb'),\n",
    "           bottleneck_features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save bottleneck_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0831 22:13:39.319429 140695323678528 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0831 22:13:39.320162 140695323678528 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0831 22:13:39.322047 140695323678528 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0831 22:13:39.340845 140695323678528 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 505 validated image filenames.\n",
      "Found 127 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "save_bottleneck_features(train_df,test_df,'eyewear',16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick tuning of top models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_top_model(train_df, test_df, epoch, batch_size, label):\n",
    "    '''\n",
    "    inputs:\n",
    "    train_df, test_df: dataframes saved in pickle_files to generate train and test labels \n",
    "    epoch: num of epochs in fit \n",
    "    batch_size: same as image generator batch size \n",
    "    label: a string, eyewear, hat, or beard\n",
    "    output:\n",
    "    saves model weights in a folder \n",
    "    '''\n",
    "    train_data = np.load(open('../tuning_data/bottleneck_features_train_eyewears_3.npy','rb'))\n",
    "    # make sure train_data and train_label have same num of samples\n",
    "    train_label = np.array(train_df[label].map({'not_'+label:0, label:1}))[:-(train_df.shape[0]%batch_size)]\n",
    "    \n",
    "    test_data = np.load(open('../tuning_data/bottleneck_features_test_eyewears_3.npy','rb'))\n",
    "    test_label = np.array(test_df[label].map({'not_'+label:0, label:1}))[:-(test_df.shape[0]%batch_size)]\n",
    "    \n",
    "    # build top model\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # compile model \n",
    "    model.compile(optimizer='rmsprop',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    # checkpoint for best weights \n",
    "    filepath=\"../tuning_data/best_bottleneck_vgg_model_eyewears_3.h5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    \n",
    "    # fit model \n",
    "    model.fit(train_data, train_label,\n",
    "             epochs=epoch,\n",
    "             batch_size=batch_size,\n",
    "             validation_data=(test_data,test_label),\n",
    "             callbacks=callbacks_list)\n",
    "    del model\n",
    "    keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run train_top_model and save results in tuning_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0831 22:13:48.482006 140695323678528 deprecation.py:506] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0831 22:13:48.496432 140695323678528 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0831 22:13:48.507232 140695323678528 deprecation.py:323] From /home/mindy/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 496 samples, validate on 112 samples\n",
      "Epoch 1/50\n",
      "496/496 [==============================] - 1s 1ms/step - loss: 4.1279 - acc: 0.5383 - val_loss: 1.0766 - val_acc: 0.5893\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.58929, saving model to ../tuning_data/best_bottleneck_vgg_model_eyewears_3.h5\n",
      "Epoch 2/50\n",
      "496/496 [==============================] - 0s 278us/step - loss: 1.2536 - acc: 0.6331 - val_loss: 0.5363 - val_acc: 0.7321\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.58929 to 0.73214, saving model to ../tuning_data/best_bottleneck_vgg_model_eyewears_3.h5\n",
      "Epoch 3/50\n",
      "496/496 [==============================] - 0s 286us/step - loss: 0.7357 - acc: 0.7440 - val_loss: 0.3180 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.73214 to 0.86607, saving model to ../tuning_data/best_bottleneck_vgg_model_eyewears_3.h5\n",
      "Epoch 4/50\n",
      "496/496 [==============================] - 0s 281us/step - loss: 0.5202 - acc: 0.7863 - val_loss: 0.3577 - val_acc: 0.8393\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.86607\n",
      "Epoch 5/50\n",
      "496/496 [==============================] - 0s 291us/step - loss: 0.6381 - acc: 0.8044 - val_loss: 0.2756 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.86607 to 0.89286, saving model to ../tuning_data/best_bottleneck_vgg_model_eyewears_3.h5\n",
      "Epoch 6/50\n",
      "496/496 [==============================] - 0s 295us/step - loss: 0.2498 - acc: 0.9153 - val_loss: 0.4038 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.89286\n",
      "Epoch 7/50\n",
      "496/496 [==============================] - 0s 292us/step - loss: 0.3244 - acc: 0.8851 - val_loss: 0.3285 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.89286\n",
      "Epoch 8/50\n",
      "496/496 [==============================] - 0s 296us/step - loss: 0.3498 - acc: 0.8831 - val_loss: 0.3802 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.89286\n",
      "Epoch 9/50\n",
      "496/496 [==============================] - 0s 304us/step - loss: 0.2073 - acc: 0.9173 - val_loss: 0.3242 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.89286\n",
      "Epoch 10/50\n",
      "496/496 [==============================] - 0s 284us/step - loss: 0.1732 - acc: 0.9274 - val_loss: 0.3093 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.89286 to 0.90179, saving model to ../tuning_data/best_bottleneck_vgg_model_eyewears_3.h5\n",
      "Epoch 11/50\n",
      "496/496 [==============================] - 0s 290us/step - loss: 0.1843 - acc: 0.9496 - val_loss: 0.2628 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.90179 to 0.92857, saving model to ../tuning_data/best_bottleneck_vgg_model_eyewears_3.h5\n",
      "Epoch 12/50\n",
      "496/496 [==============================] - 0s 296us/step - loss: 0.1654 - acc: 0.9456 - val_loss: 0.2689 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92857\n",
      "Epoch 13/50\n",
      "496/496 [==============================] - 0s 290us/step - loss: 0.1278 - acc: 0.9758 - val_loss: 0.3667 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.92857\n",
      "Epoch 14/50\n",
      "496/496 [==============================] - 0s 295us/step - loss: 0.1904 - acc: 0.9577 - val_loss: 0.5185 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.92857\n",
      "Epoch 15/50\n",
      "496/496 [==============================] - 0s 291us/step - loss: 0.0273 - acc: 0.9919 - val_loss: 0.3496 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.92857\n",
      "Epoch 16/50\n",
      "496/496 [==============================] - 0s 297us/step - loss: 0.1928 - acc: 0.9617 - val_loss: 0.3528 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.92857\n",
      "Epoch 17/50\n",
      "496/496 [==============================] - 0s 299us/step - loss: 0.0494 - acc: 0.9778 - val_loss: 0.3423 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.92857\n",
      "Epoch 18/50\n",
      "496/496 [==============================] - 0s 283us/step - loss: 0.1812 - acc: 0.9577 - val_loss: 0.4479 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.92857\n",
      "Epoch 19/50\n",
      "496/496 [==============================] - 0s 289us/step - loss: 0.0099 - acc: 0.9960 - val_loss: 0.4242 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.92857\n",
      "Epoch 20/50\n",
      "496/496 [==============================] - 0s 294us/step - loss: 0.0872 - acc: 0.9718 - val_loss: 1.2294 - val_acc: 0.7589\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.92857\n",
      "Epoch 21/50\n",
      "496/496 [==============================] - 0s 294us/step - loss: 0.0479 - acc: 0.9839 - val_loss: 0.7090 - val_acc: 0.8125\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.92857\n",
      "Epoch 22/50\n",
      "496/496 [==============================] - 0s 288us/step - loss: 0.0829 - acc: 0.9738 - val_loss: 0.6890 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.92857\n",
      "Epoch 23/50\n",
      "496/496 [==============================] - 0s 299us/step - loss: 0.0851 - acc: 0.9778 - val_loss: 0.3683 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.92857\n",
      "Epoch 24/50\n",
      "496/496 [==============================] - 0s 301us/step - loss: 0.0181 - acc: 0.9940 - val_loss: 0.5038 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.92857\n",
      "Epoch 25/50\n",
      "496/496 [==============================] - 0s 295us/step - loss: 0.1252 - acc: 0.9698 - val_loss: 0.4587 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.92857\n",
      "Epoch 26/50\n",
      "496/496 [==============================] - 0s 291us/step - loss: 0.0134 - acc: 0.9960 - val_loss: 0.4572 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.92857\n",
      "Epoch 27/50\n",
      "496/496 [==============================] - 0s 296us/step - loss: 0.0146 - acc: 0.9940 - val_loss: 1.8949 - val_acc: 0.6875\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.92857\n",
      "Epoch 28/50\n",
      "496/496 [==============================] - 0s 278us/step - loss: 0.1218 - acc: 0.9758 - val_loss: 0.5095 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.92857\n",
      "Epoch 29/50\n",
      "496/496 [==============================] - 0s 287us/step - loss: 0.0039 - acc: 0.9980 - val_loss: 0.7852 - val_acc: 0.8482\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.92857\n",
      "Epoch 30/50\n",
      "496/496 [==============================] - 0s 291us/step - loss: 0.0423 - acc: 0.9859 - val_loss: 0.4953 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.92857\n",
      "Epoch 31/50\n",
      "496/496 [==============================] - 0s 306us/step - loss: 0.0390 - acc: 0.9839 - val_loss: 0.5647 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.92857\n",
      "Epoch 32/50\n",
      "496/496 [==============================] - 0s 296us/step - loss: 0.0312 - acc: 0.9899 - val_loss: 0.3656 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.92857\n",
      "Epoch 33/50\n",
      "496/496 [==============================] - 0s 287us/step - loss: 0.0492 - acc: 0.9859 - val_loss: 0.5360 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.92857\n",
      "Epoch 34/50\n",
      "496/496 [==============================] - 0s 304us/step - loss: 0.0418 - acc: 0.9899 - val_loss: 0.4408 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.92857\n",
      "Epoch 35/50\n",
      "496/496 [==============================] - 0s 296us/step - loss: 6.6287e-04 - acc: 1.0000 - val_loss: 0.5041 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.92857\n",
      "Epoch 36/50\n",
      "496/496 [==============================] - 0s 301us/step - loss: 0.0238 - acc: 0.9919 - val_loss: 0.8963 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.92857\n",
      "Epoch 37/50\n",
      "496/496 [==============================] - 0s 297us/step - loss: 0.0032 - acc: 0.9980 - val_loss: 0.8401 - val_acc: 0.8482\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.92857\n",
      "Epoch 38/50\n",
      "496/496 [==============================] - 0s 300us/step - loss: 0.0934 - acc: 0.9798 - val_loss: 0.6713 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.92857\n",
      "Epoch 39/50\n",
      "496/496 [==============================] - 0s 296us/step - loss: 4.5798e-04 - acc: 1.0000 - val_loss: 0.5720 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.92857\n",
      "Epoch 40/50\n",
      "496/496 [==============================] - 0s 300us/step - loss: 0.0306 - acc: 0.9899 - val_loss: 0.9110 - val_acc: 0.8393\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.92857\n",
      "Epoch 41/50\n",
      "496/496 [==============================] - 0s 295us/step - loss: 0.0071 - acc: 0.9960 - val_loss: 0.5590 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.92857\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496/496 [==============================] - 0s 283us/step - loss: 0.0539 - acc: 0.9859 - val_loss: 0.4655 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.92857\n",
      "Epoch 43/50\n",
      "496/496 [==============================] - 0s 283us/step - loss: 1.1601e-04 - acc: 1.0000 - val_loss: 0.4603 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.92857\n",
      "Epoch 44/50\n",
      "496/496 [==============================] - 0s 280us/step - loss: 0.0168 - acc: 0.9960 - val_loss: 0.7210 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.92857\n",
      "Epoch 45/50\n",
      "496/496 [==============================] - 0s 295us/step - loss: 0.0065 - acc: 0.9960 - val_loss: 0.5674 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.92857\n",
      "Epoch 46/50\n",
      "496/496 [==============================] - 0s 292us/step - loss: 0.0065 - acc: 0.9980 - val_loss: 0.5213 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.92857\n",
      "Epoch 47/50\n",
      "496/496 [==============================] - 0s 289us/step - loss: 0.0605 - acc: 0.9879 - val_loss: 0.7302 - val_acc: 0.8839\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.92857\n",
      "Epoch 48/50\n",
      "496/496 [==============================] - 0s 288us/step - loss: 2.6470e-04 - acc: 1.0000 - val_loss: 0.9914 - val_acc: 0.8393\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.92857\n",
      "Epoch 49/50\n",
      "496/496 [==============================] - 0s 284us/step - loss: 0.0415 - acc: 0.9940 - val_loss: 0.5179 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.92857\n",
      "Epoch 50/50\n",
      "496/496 [==============================] - 0s 282us/step - loss: 0.0072 - acc: 0.9960 - val_loss: 0.5446 - val_acc: 0.8839\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.92857\n"
     ]
    }
   ],
   "source": [
    "train_top_model(train_df, test_df, 50, 16, 'eyewear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tune Top Model to improve accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_model(train_df, test_df,epoch, batch_size,label, print_model = True):\n",
    "    # build VGG16 model and freeze top layers\n",
    "    # input_shape: width, height, RGB (from image generator)\n",
    "    model_vgg = VGG16(weights='imagenet',include_top=False, input_shape=(224,224,3))\n",
    "    # build top model\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=model_vgg.output_shape[1:]))\n",
    "    top_model.add(Dense(256,activation='relu'))\n",
    "    top_model.add(Dropout(0.5))\n",
    "    top_model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # load saved weights to fine tune parameters \n",
    "    top_model.load_weights('../tuning_data/best_bottleneck_vgg_model_eyewears_3.h5')\n",
    "    # add top model to model\n",
    "    model = Model(inputs=model_vgg.input, outputs=top_model(model_vgg.output))\n",
    "    # we will tune last 5 layers of the model: block5 and fully connected layer \n",
    "    for layer in model.layers[:15]:\n",
    "        layer.trainable = False\n",
    "    # we can tune the parameters for lr and momentum later to get better results\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "             optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "             metrics=['accuracy'])\n",
    "    # prepare train generator using data augmentation to battle small sample size \n",
    "    train_gen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        zoom_range= [0.8,1.7],\n",
    "        shear_range=0.2,\n",
    "        rotation_range = 40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        preprocessing_function=preprocess_input)\n",
    "    # not want to augment the test \n",
    "    test_gen = ImageDataGenerator(\n",
    "            rescale = 1./255,\n",
    "            preprocessing_function=preprocess_input)\n",
    "    \n",
    "    train_generator =  train_gen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory='../data/pics',\n",
    "    x_col='pic_id',\n",
    "    y_col=label,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(224,224),\n",
    "    class_mode = 'binary')\n",
    "    \n",
    "    test_generator =  test_gen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory='../data/pics',\n",
    "    x_col='pic_id',\n",
    "    y_col=label,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(224,224),\n",
    "    class_mode = 'binary')\n",
    "    \n",
    "    # checkpoint for best weights \n",
    "    filepath=\"../tuning_data/best_vgg_model_eyewears_3.h5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    \n",
    "    # run and fit model \n",
    "    result = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_df.shape[0]//batch_size,\n",
    "    epochs=epoch,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_df.shape[0]//batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list)\n",
    "    \n",
    "    if print_model:\n",
    "        model.summary()\n",
    "        \n",
    "    del model\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    return result      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save model history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 505 validated image filenames belonging to 2 classes.\n",
      "Found 127 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 7s 221ms/step - loss: 2.0686 - acc: 0.3121 - val_loss: 0.7907 - val_acc: 0.4286\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.42857, saving model to ../tuning_data/best_vgg_model_eyewears_3.h5\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 7s 219ms/step - loss: 0.7594 - acc: 0.5058 - val_loss: 0.7204 - val_acc: 0.4505\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.42857 to 0.45045, saving model to ../tuning_data/best_vgg_model_eyewears_3.h5\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 6s 198ms/step - loss: 0.7304 - acc: 0.4781 - val_loss: 0.7036 - val_acc: 0.4775\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.45045 to 0.47748, saving model to ../tuning_data/best_vgg_model_eyewears_3.h5\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 7s 213ms/step - loss: 0.7116 - acc: 0.4841 - val_loss: 0.6886 - val_acc: 0.5225\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.47748 to 0.52252, saving model to ../tuning_data/best_vgg_model_eyewears_3.h5\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 6s 206ms/step - loss: 0.6948 - acc: 0.5161 - val_loss: 0.7095 - val_acc: 0.4234\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.52252\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 6s 192ms/step - loss: 0.7057 - acc: 0.5020 - val_loss: 0.6758 - val_acc: 0.5766\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.52252 to 0.57658, saving model to ../tuning_data/best_vgg_model_eyewears_3.h5\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 7s 213ms/step - loss: 0.7039 - acc: 0.5366 - val_loss: 0.6664 - val_acc: 0.6306\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.57658 to 0.63063, saving model to ../tuning_data/best_vgg_model_eyewears_3.h5\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 6s 193ms/step - loss: 0.6920 - acc: 0.5446 - val_loss: 0.6724 - val_acc: 0.5495\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.63063\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 7s 210ms/step - loss: 0.6752 - acc: 0.5786 - val_loss: 0.6582 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.63063\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 7s 212ms/step - loss: 0.6729 - acc: 0.5608 - val_loss: 0.6303 - val_acc: 0.6847\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.63063 to 0.68468, saving model to ../tuning_data/best_vgg_model_eyewears_3.h5\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 7s 216ms/step - loss: 0.6644 - acc: 0.5663 - val_loss: 0.6195 - val_acc: 0.6036\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.68468\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 6s 206ms/step - loss: 0.6447 - acc: 0.6458 - val_loss: 0.6063 - val_acc: 0.6396\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.68468\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 6s 205ms/step - loss: 0.6372 - acc: 0.6520 - val_loss: 0.5879 - val_acc: 0.6937\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.68468 to 0.69369, saving model to ../tuning_data/best_vgg_model_eyewears_3.h5\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 6s 201ms/step - loss: 0.6133 - acc: 0.6754 - val_loss: 0.4941 - val_acc: 0.7207\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.69369 to 0.72072, saving model to ../tuning_data/best_vgg_model_eyewears_3.h5\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 6s 188ms/step - loss: 0.5723 - acc: 0.6993 - val_loss: 0.5634 - val_acc: 0.6937\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.72072\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 6s 209ms/step - loss: 0.5504 - acc: 0.7146 - val_loss: 0.4716 - val_acc: 0.7297\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.72072 to 0.72973, saving model to ../tuning_data/best_vgg_model_eyewears_3.h5\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 6s 208ms/step - loss: 0.5065 - acc: 0.7641 - val_loss: 0.4273 - val_acc: 0.7679\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.72973 to 0.76786, saving model to ../tuning_data/best_vgg_model_eyewears_3.h5\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 7s 215ms/step - loss: 0.4596 - acc: 0.8013 - val_loss: 0.4465 - val_acc: 0.7477\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.76786\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 6s 204ms/step - loss: 0.4197 - acc: 0.8129 - val_loss: 0.2803 - val_acc: 0.9009\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.76786 to 0.90090, saving model to ../tuning_data/best_vgg_model_eyewears_3.h5\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 6s 205ms/step - loss: 0.3835 - acc: 0.8517 - val_loss: 0.3619 - val_acc: 0.7568\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.90090\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 6s 204ms/step - loss: 0.3148 - acc: 0.8976 - val_loss: 0.2549 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.90090 to 0.92793, saving model to ../tuning_data/best_vgg_model_eyewears_3.h5\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 6s 201ms/step - loss: 0.3116 - acc: 0.8831 - val_loss: 0.2366 - val_acc: 0.8919\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.92793\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 6s 206ms/step - loss: 0.2829 - acc: 0.8996 - val_loss: 0.2476 - val_acc: 0.9099\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.92793\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 6s 192ms/step - loss: 0.2419 - acc: 0.9077 - val_loss: 0.1753 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.92793 to 0.96396, saving model to ../tuning_data/best_vgg_model_eyewears_3.h5\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 6s 208ms/step - loss: 0.2151 - acc: 0.9203 - val_loss: 0.2399 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.96396\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 7s 216ms/step - loss: 0.2432 - acc: 0.9102 - val_loss: 0.1242 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.96396 to 0.98198, saving model to ../tuning_data/best_vgg_model_eyewears_3.h5\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 6s 200ms/step - loss: 0.2139 - acc: 0.9314 - val_loss: 0.1113 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.98198\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 6s 203ms/step - loss: 0.2061 - acc: 0.9203 - val_loss: 0.1685 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.98198\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 6s 204ms/step - loss: 0.2022 - acc: 0.9214 - val_loss: 0.1064 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.98198 to 0.99099, saving model to ../tuning_data/best_vgg_model_eyewears_3.h5\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 7s 214ms/step - loss: 0.1774 - acc: 0.9239 - val_loss: 0.1543 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.99099\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 6s 202ms/step - loss: 0.1866 - acc: 0.9274 - val_loss: 0.1110 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.99099\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 6s 197ms/step - loss: 0.1800 - acc: 0.9344 - val_loss: 0.1076 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.99099\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 6s 200ms/step - loss: 0.1635 - acc: 0.9380 - val_loss: 0.1241 - val_acc: 0.9821\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.99099\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 7s 222ms/step - loss: 0.1609 - acc: 0.9455 - val_loss: 0.1190 - val_acc: 0.9550\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.99099\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 7s 213ms/step - loss: 0.1483 - acc: 0.9516 - val_loss: 0.1409 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.99099\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 6s 207ms/step - loss: 0.1490 - acc: 0.9521 - val_loss: 0.1677 - val_acc: 0.9550\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.99099\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 7s 220ms/step - loss: 0.1067 - acc: 0.9677 - val_loss: 0.0524 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.99099\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 6s 199ms/step - loss: 0.1391 - acc: 0.9480 - val_loss: 0.1253 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.99099\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 6s 197ms/step - loss: 0.1344 - acc: 0.9456 - val_loss: 0.1402 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.99099\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 7s 211ms/step - loss: 0.1519 - acc: 0.9536 - val_loss: 0.0967 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.99099\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 6s 201ms/step - loss: 0.1346 - acc: 0.9445 - val_loss: 0.1428 - val_acc: 0.9554\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.99099\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 7s 229ms/step - loss: 0.1139 - acc: 0.9556 - val_loss: 0.0569 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.99099 to 0.99099, saving model to ../tuning_data/best_vgg_model_eyewears_3.h5\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 6s 204ms/step - loss: 0.1240 - acc: 0.9496 - val_loss: 0.1141 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.99099\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 7s 212ms/step - loss: 0.1209 - acc: 0.9577 - val_loss: 0.1254 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.99099\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 6s 190ms/step - loss: 0.0857 - acc: 0.9692 - val_loss: 0.1668 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.99099\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 7s 211ms/step - loss: 0.1109 - acc: 0.9597 - val_loss: 0.1134 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.99099\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 6s 202ms/step - loss: 0.0961 - acc: 0.9617 - val_loss: 0.1004 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.99099\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 6s 208ms/step - loss: 0.0892 - acc: 0.9723 - val_loss: 0.1001 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.99099\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 6s 208ms/step - loss: 0.1226 - acc: 0.9576 - val_loss: 0.0940 - val_acc: 0.9911\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.99099 to 0.99107, saving model to ../tuning_data/best_vgg_model_eyewears_3.h5\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 7s 213ms/step - loss: 0.0917 - acc: 0.9617 - val_loss: 0.1561 - val_acc: 0.9550\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.99107\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 6s 201ms/step - loss: 0.0759 - acc: 0.9818 - val_loss: 0.0381 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.99107\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 6s 208ms/step - loss: 0.1017 - acc: 0.9637 - val_loss: 0.1317 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.99107\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 6s 205ms/step - loss: 0.1045 - acc: 0.9617 - val_loss: 0.0249 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00053: val_acc improved from 0.99107 to 1.00000, saving model to ../tuning_data/best_vgg_model_eyewears_3.h5\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 6s 199ms/step - loss: 0.0797 - acc: 0.9723 - val_loss: 0.0958 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 1.00000\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 7s 212ms/step - loss: 0.0756 - acc: 0.9758 - val_loss: 0.0946 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 1.00000\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 6s 194ms/step - loss: 0.0933 - acc: 0.9758 - val_loss: 0.0899 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 1.00000\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 6s 202ms/step - loss: 0.0812 - acc: 0.9662 - val_loss: 0.0310 - val_acc: 0.9911\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 1.00000\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 7s 210ms/step - loss: 0.0678 - acc: 0.9798 - val_loss: 0.1570 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 1.00000\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 7s 211ms/step - loss: 0.0697 - acc: 0.9758 - val_loss: 0.0814 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 1.00000\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 7s 211ms/step - loss: 0.0677 - acc: 0.9798 - val_loss: 0.0433 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 1.00000\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 6s 208ms/step - loss: 0.0604 - acc: 0.9778 - val_loss: 0.1531 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 1.00000\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 6s 199ms/step - loss: 0.0865 - acc: 0.9657 - val_loss: 0.0326 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 1.00000\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 6s 209ms/step - loss: 0.0709 - acc: 0.9758 - val_loss: 0.1013 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 1.00000\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 6s 198ms/step - loss: 0.0802 - acc: 0.9697 - val_loss: 0.0949 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 1.00000\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 6s 204ms/step - loss: 0.0922 - acc: 0.9682 - val_loss: 0.0732 - val_acc: 0.9911\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 1.00000\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 7s 219ms/step - loss: 0.0770 - acc: 0.9758 - val_loss: 0.1527 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 1.00000\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 7s 220ms/step - loss: 0.0624 - acc: 0.9778 - val_loss: 0.0952 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 1.00000\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 7s 216ms/step - loss: 0.0618 - acc: 0.9798 - val_loss: 0.0761 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 1.00000\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 6s 203ms/step - loss: 0.0670 - acc: 0.9758 - val_loss: 0.0676 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 1.00000\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 6s 193ms/step - loss: 0.0600 - acc: 0.9738 - val_loss: 0.0928 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 1.00000\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 7s 210ms/step - loss: 0.0728 - acc: 0.9738 - val_loss: 0.0973 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 1.00000\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 6s 196ms/step - loss: 0.0520 - acc: 0.9859 - val_loss: 0.0818 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 1.00000\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 6s 199ms/step - loss: 0.0553 - acc: 0.9803 - val_loss: 0.1100 - val_acc: 0.9732\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 1.00000\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 7s 221ms/step - loss: 0.0537 - acc: 0.9803 - val_loss: 0.1025 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 1.00000\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 6s 209ms/step - loss: 0.0574 - acc: 0.9738 - val_loss: 0.0136 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 1.00000\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 6s 208ms/step - loss: 0.0556 - acc: 0.9819 - val_loss: 0.1933 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 1.00000\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 6s 204ms/step - loss: 0.0529 - acc: 0.9798 - val_loss: 0.0147 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 1.00000\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 6s 193ms/step - loss: 0.0626 - acc: 0.9758 - val_loss: 0.1343 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 1.00000\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 6s 209ms/step - loss: 0.0551 - acc: 0.9768 - val_loss: 0.1035 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 1.00000\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 6s 201ms/step - loss: 0.0562 - acc: 0.9778 - val_loss: 0.1102 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 1.00000\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 6s 202ms/step - loss: 0.0596 - acc: 0.9844 - val_loss: 0.1050 - val_acc: 0.9821\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 1.00000\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 7s 222ms/step - loss: 0.0407 - acc: 0.9839 - val_loss: 0.1085 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 1.00000\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 7s 212ms/step - loss: 0.0435 - acc: 0.9859 - val_loss: 0.0879 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 1.00000\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 6s 209ms/step - loss: 0.0314 - acc: 0.9960 - val_loss: 0.0827 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 1.00000\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 6s 187ms/step - loss: 0.0645 - acc: 0.9823 - val_loss: 0.1555 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 1.00000\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 6s 209ms/step - loss: 0.0704 - acc: 0.9657 - val_loss: 0.0400 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 1.00000\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 6s 205ms/step - loss: 0.0492 - acc: 0.9859 - val_loss: 0.0857 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 1.00000\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 6s 202ms/step - loss: 0.0441 - acc: 0.9879 - val_loss: 0.1145 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 1.00000\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 6s 209ms/step - loss: 0.0657 - acc: 0.9743 - val_loss: 0.1094 - val_acc: 0.9821\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 1.00000\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 7s 219ms/step - loss: 0.0390 - acc: 0.9859 - val_loss: 0.1084 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 1.00000\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 6s 197ms/step - loss: 0.0435 - acc: 0.9879 - val_loss: 0.0884 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 1.00000\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 6s 210ms/step - loss: 0.0409 - acc: 0.9859 - val_loss: 0.1267 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 1.00000\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 6s 203ms/step - loss: 0.0279 - acc: 0.9939 - val_loss: 0.1190 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 1.00000\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 6s 205ms/step - loss: 0.0405 - acc: 0.9818 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 1.00000\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 6s 194ms/step - loss: 0.0397 - acc: 0.9899 - val_loss: 0.1254 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 1.00000\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 6s 202ms/step - loss: 0.0431 - acc: 0.9819 - val_loss: 0.0889 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 1.00000\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 7s 211ms/step - loss: 0.0273 - acc: 0.9939 - val_loss: 0.1153 - val_acc: 0.9821\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 1.00000\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 7s 219ms/step - loss: 0.0413 - acc: 0.9823 - val_loss: 0.1091 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 1.00000\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 7s 214ms/step - loss: 0.0403 - acc: 0.9919 - val_loss: 0.1074 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 1.00000\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 7s 212ms/step - loss: 0.0877 - acc: 0.9657 - val_loss: 0.1095 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 1.00000\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 6423041   \n",
      "=================================================================\n",
      "Total params: 21,137,729\n",
      "Trainable params: 13,502,465\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_history = fine_tune_model(train_df, test_df,100,16,'eyewear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest test accuracy: 1.0\n",
      "------------------\n",
      "highest train accuracy: 0.9959677419354839\n"
     ]
    }
   ],
   "source": [
    "highest_val_acc, highest_train_acc = max(model_history.history['val_acc']), max(model_history.history['acc'])\n",
    "print(f'highest test accuracy: {highest_val_acc}')\n",
    "print('------------------')\n",
    "print(f'highest train accuracy: {highest_train_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowest test loss: 0.005892951083411505\n",
      "------------------\n",
      "lowest train loss: 0.0274533739766765\n"
     ]
    }
   ],
   "source": [
    "lowest_val_loss, lowest_train_loss = min(model_history.history['val_loss']), min(model_history.history['loss'])\n",
    "print(f'lowest test loss: {lowest_val_loss}')\n",
    "print('------------------')\n",
    "print(f'lowest train loss: {lowest_train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model_history.history['val_acc'], color = 'red', label = 'test')\n",
    "plt.plot(model_history.history['acc'], color = 'blue', label = 'train')\n",
    "plt.title('accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model_history.history['val_loss'], color = 'red', label = 'test')\n",
    "plt.plot(model_history.history['loss'], color = 'blue', label = 'train')\n",
    "plt.title('loss')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model artchitecture \n",
    "eyewear_model = model_history.model\n",
    "eyewear_model_json = eyewear_model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "with open(\"../tuning_dataeyewear_model.json\", \"w\") as json_file:\n",
    "    json_file.write(eyewear_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open('../tuning_data/eyewear_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model_eyewear = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model weight \n",
    "loaded_model_eyewear.load_weights('../tuning_data/best_vgg_model_eyewears.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator =  test_gen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory='../data/pics',\n",
    "    x_col='pic_id',\n",
    "    y_col='eyewear',\n",
    "    batch_size=16,\n",
    "    target_size=(150,150),\n",
    "    class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_eyewear.compile(loss='binary_crossentropy',\n",
    "             optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_model_eyewear.evaluate_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature, label = next(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(feature[10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "np.around(loaded_model_eyewear.predict_generator(test_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
