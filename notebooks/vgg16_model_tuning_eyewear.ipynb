{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning Tuning_EyeWear:\n",
    "  * model parameter and other information can be found below:\n",
    "     * [source](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)\n",
    "     \n",
    "  * base_model: use vgg16 and freeze at bottleneck layer (stop right before flatten layer) \n",
    "  * top_model: tune dense layers (parameters are inspired by source)\n",
    "     * batch_size 16 seems to work best for small data set \n",
    "\n",
    "##### warnings: make sure to restart kernel in between running different model tuning \n",
    "  \n",
    "---\n",
    "#### This cell is required in order to use GPU for running the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0829 11:01:20.248958 139794952161088 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0829 11:01:20.249930 139794952161088 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "                                    # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
    "keras.backend.get_session().run(tf.global_variables_initializer())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Import train_df and test_df for eyewears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('../pickle_files/train_df_glasses.pkl')\n",
    "test_df = pd.read_pickle('../pickle_files/test_df_glasses.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get bottleneck features to tune top models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_bottleneck_features(train_df, test_df, label, batch_size):\n",
    "    '''\n",
    "    inputs:\n",
    "    train_df, test_df: train and test dataframes saved in pickle_files folder\n",
    "    label: a string, eyewear, hat, or beard\n",
    "    batch_size: process images in batches\n",
    "    outputs:\n",
    "    saves bottleneck features inside folder tuning_data as npy file\n",
    "    '''\n",
    "    # intialize the vgg16 model \n",
    "    # make sure not to train the top layers \n",
    "    base_model = VGG16(weights = 'imagenet', include_top = False)\n",
    "    # create train_generator and test_generator to get bottleneck inputs for train and test df \n",
    "    datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "    # make sure shuffle is False so we know the label follows the sequence of the dataframe \n",
    "    # so we can tune top_model \n",
    "    train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory='../data/pics',\n",
    "    x_col='pic_id',\n",
    "    y_col=label,\n",
    "    batch_size=batch_size,\n",
    "    shuffle = False,\n",
    "    target_size=(150,150),\n",
    "    class_mode = None)\n",
    "    # get features saved as .npy in tunign_data folder \n",
    "    bottleneck_features_train = base_model.predict_generator(\n",
    "        train_generator, train_df.shape[0]//batch_size)\n",
    "    np.save(open('../tuning_data/bottleneck_features_train_eyewears.npy','wb'),\n",
    "           bottleneck_features_train)\n",
    "    \n",
    "    test_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory='../data/pics',\n",
    "    x_col='pic_id',\n",
    "    y_col=label,\n",
    "    batch_size=batch_size,\n",
    "    shuffle = False,\n",
    "    target_size=(150,150),\n",
    "    class_mode = None)\n",
    "    bottleneck_features_test = base_model.predict_generator(\n",
    "        test_generator, test_df.shape[0]//batch_size)\n",
    "    np.save(open('../tuning_data/bottleneck_features_test_eyewears.npy','wb'),\n",
    "           bottleneck_features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save bottleneck_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0828 23:26:55.309392 139702605895488 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0828 23:26:55.310434 139702605895488 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0828 23:26:55.312547 139702605895488 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0828 23:26:55.332221 139702605895488 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 505 validated image filenames.\n",
      "Found 127 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "save_bottleneck_features(train_df,test_df,'eyewear',16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick tuning of top models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_top_model(train_df, test_df, epoch, batch_size, label):\n",
    "    '''\n",
    "    inputs:\n",
    "    train_df, test_df: dataframes saved in pickle_files to generate train and test labels \n",
    "    epoch: num of epochs in fit \n",
    "    batch_size: same as image generator batch size \n",
    "    label: a string, eyewear, hat, or beard\n",
    "    output:\n",
    "    saves model weights in a folder \n",
    "    '''\n",
    "    train_data = np.load(open('../tuning_data/bottleneck_features_train_eyewears.npy','rb'))\n",
    "    # make sure train_data and train_label have same num of samples\n",
    "    train_label = np.array(train_df[label].map({'not_'+label:0, label:1}))[:-(train_df.shape[0]%batch_size)]\n",
    "    \n",
    "    test_data = np.load(open('../tuning_data/bottleneck_features_test_eyewears.npy','rb'))\n",
    "    test_label = np.array(test_df[label].map({'not_'+label:0, label:1}))[:-(test_df.shape[0]%batch_size)]\n",
    "    \n",
    "    # build top model\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='rmsprop',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(train_data, train_label,\n",
    "             epochs=epoch,\n",
    "             batch_size=batch_size,\n",
    "             validation_data=(test_data,test_label))\n",
    "    model.save_weights('../tuning_data/bottleneck_vgg_model_eyewears.h5')\n",
    "    del model\n",
    "    keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run train_top_model and save results in tuning_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0828 23:27:07.051556 139702605895488 deprecation.py:506] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0828 23:27:07.067415 139702605895488 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0828 23:27:07.077111 139702605895488 deprecation.py:323] From /home/mindy/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 496 samples, validate on 112 samples\n",
      "Epoch 1/50\n",
      "496/496 [==============================] - 0s 845us/step - loss: 1.4208 - acc: 0.6573 - val_loss: 0.3576 - val_acc: 0.8750\n",
      "Epoch 2/50\n",
      "496/496 [==============================] - 0s 200us/step - loss: 0.5058 - acc: 0.7964 - val_loss: 0.3255 - val_acc: 0.8929\n",
      "Epoch 3/50\n",
      "496/496 [==============================] - 0s 192us/step - loss: 0.3476 - acc: 0.8589 - val_loss: 0.3781 - val_acc: 0.8839\n",
      "Epoch 4/50\n",
      "496/496 [==============================] - 0s 198us/step - loss: 0.3508 - acc: 0.8770 - val_loss: 0.3166 - val_acc: 0.9018\n",
      "Epoch 5/50\n",
      "496/496 [==============================] - 0s 205us/step - loss: 0.2407 - acc: 0.9052 - val_loss: 0.5171 - val_acc: 0.7946\n",
      "Epoch 6/50\n",
      "496/496 [==============================] - 0s 210us/step - loss: 0.2588 - acc: 0.8931 - val_loss: 1.2488 - val_acc: 0.7321\n",
      "Epoch 7/50\n",
      "496/496 [==============================] - 0s 211us/step - loss: 0.2591 - acc: 0.9032 - val_loss: 0.3773 - val_acc: 0.8929\n",
      "Epoch 8/50\n",
      "496/496 [==============================] - 0s 205us/step - loss: 0.0948 - acc: 0.9698 - val_loss: 0.9434 - val_acc: 0.7232\n",
      "Epoch 9/50\n",
      "496/496 [==============================] - 0s 212us/step - loss: 0.1162 - acc: 0.9556 - val_loss: 0.4407 - val_acc: 0.9107\n",
      "Epoch 10/50\n",
      "496/496 [==============================] - 0s 202us/step - loss: 0.1828 - acc: 0.9375 - val_loss: 0.4044 - val_acc: 0.9018\n",
      "Epoch 11/50\n",
      "496/496 [==============================] - 0s 208us/step - loss: 0.0654 - acc: 0.9718 - val_loss: 0.4797 - val_acc: 0.8929\n",
      "Epoch 12/50\n",
      "496/496 [==============================] - 0s 200us/step - loss: 0.0919 - acc: 0.9577 - val_loss: 0.6428 - val_acc: 0.9018\n",
      "Epoch 13/50\n",
      "496/496 [==============================] - 0s 187us/step - loss: 0.0672 - acc: 0.9657 - val_loss: 0.5759 - val_acc: 0.9018\n",
      "Epoch 14/50\n",
      "496/496 [==============================] - 0s 194us/step - loss: 0.0545 - acc: 0.9758 - val_loss: 0.5822 - val_acc: 0.9196\n",
      "Epoch 15/50\n",
      "496/496 [==============================] - 0s 197us/step - loss: 0.0414 - acc: 0.9859 - val_loss: 0.9984 - val_acc: 0.7679\n",
      "Epoch 16/50\n",
      "496/496 [==============================] - 0s 201us/step - loss: 0.0566 - acc: 0.9718 - val_loss: 0.6560 - val_acc: 0.8839\n",
      "Epoch 17/50\n",
      "496/496 [==============================] - 0s 191us/step - loss: 0.0248 - acc: 0.9879 - val_loss: 0.5871 - val_acc: 0.9018\n",
      "Epoch 18/50\n",
      "496/496 [==============================] - 0s 193us/step - loss: 0.0281 - acc: 0.9899 - val_loss: 0.6324 - val_acc: 0.8839\n",
      "Epoch 19/50\n",
      "496/496 [==============================] - 0s 198us/step - loss: 0.1136 - acc: 0.9758 - val_loss: 0.6641 - val_acc: 0.8839\n",
      "Epoch 20/50\n",
      "496/496 [==============================] - 0s 190us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.7138 - val_acc: 0.9107\n",
      "Epoch 21/50\n",
      "496/496 [==============================] - 0s 202us/step - loss: 0.0493 - acc: 0.9819 - val_loss: 0.7056 - val_acc: 0.8929\n",
      "Epoch 22/50\n",
      "496/496 [==============================] - 0s 199us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.7508 - val_acc: 0.8750\n",
      "Epoch 23/50\n",
      "496/496 [==============================] - 0s 202us/step - loss: 0.0364 - acc: 0.9859 - val_loss: 0.7534 - val_acc: 0.8839\n",
      "Epoch 24/50\n",
      "496/496 [==============================] - 0s 206us/step - loss: 0.0144 - acc: 0.9980 - val_loss: 0.7842 - val_acc: 0.8839  \n",
      "Epoch 25/50\n",
      "496/496 [==============================] - 0s 205us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 1.3321 - val_acc: 0.7946\n",
      "Epoch 26/50\n",
      "496/496 [==============================] - 0s 203us/step - loss: 0.0350 - acc: 0.9879 - val_loss: 0.7844 - val_acc: 0.8839\n",
      "Epoch 27/50\n",
      "496/496 [==============================] - 0s 192us/step - loss: 0.0049 - acc: 0.9960 - val_loss: 0.8242 - val_acc: 0.8929\n",
      "Epoch 28/50\n",
      "496/496 [==============================] - 0s 195us/step - loss: 0.0186 - acc: 0.9960 - val_loss: 0.7519 - val_acc: 0.8929\n",
      "Epoch 29/50\n",
      "496/496 [==============================] - 0s 197us/step - loss: 0.0025 - acc: 0.9980 - val_loss: 0.7873 - val_acc: 0.8750\n",
      "Epoch 30/50\n",
      "496/496 [==============================] - 0s 198us/step - loss: 0.0299 - acc: 0.9919 - val_loss: 0.8597 - val_acc: 0.9018\n",
      "Epoch 31/50\n",
      "496/496 [==============================] - 0s 203us/step - loss: 0.0037 - acc: 0.9980 - val_loss: 0.8991 - val_acc: 0.9018\n",
      "Epoch 32/50\n",
      "496/496 [==============================] - 0s 210us/step - loss: 0.0160 - acc: 0.9940 - val_loss: 0.8265 - val_acc: 0.8839\n",
      "Epoch 33/50\n",
      "496/496 [==============================] - 0s 214us/step - loss: 3.8052e-04 - acc: 1.0000 - val_loss: 0.8341 - val_acc: 0.8750\n",
      "Epoch 34/50\n",
      "496/496 [==============================] - 0s 208us/step - loss: 0.0142 - acc: 0.9919 - val_loss: 0.8238 - val_acc: 0.9018\n",
      "Epoch 35/50\n",
      "496/496 [==============================] - 0s 207us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.8949 - val_acc: 0.9018\n",
      "Epoch 36/50\n",
      "496/496 [==============================] - 0s 211us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.9018 - val_acc: 0.8929\n",
      "Epoch 37/50\n",
      "496/496 [==============================] - 0s 207us/step - loss: 0.0281 - acc: 0.9899 - val_loss: 0.9161 - val_acc: 0.8929\n",
      "Epoch 38/50\n",
      "496/496 [==============================] - 0s 208us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.9667 - val_acc: 0.8929\n",
      "Epoch 39/50\n",
      "496/496 [==============================] - 0s 207us/step - loss: 0.0047 - acc: 0.9980 - val_loss: 0.9429 - val_acc: 0.8929\n",
      "Epoch 40/50\n",
      "496/496 [==============================] - 0s 194us/step - loss: 0.0044 - acc: 0.9980 - val_loss: 0.9000 - val_acc: 0.8929\n",
      "Epoch 41/50\n",
      "496/496 [==============================] - 0s 199us/step - loss: 0.0117 - acc: 0.9940 - val_loss: 0.8740 - val_acc: 0.8929\n",
      "Epoch 42/50\n",
      "496/496 [==============================] - 0s 204us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.8958 - val_acc: 0.8929\n",
      "Epoch 43/50\n",
      "496/496 [==============================] - 0s 214us/step - loss: 0.0042 - acc: 0.9980 - val_loss: 0.9970 - val_acc: 0.8929\n",
      "Epoch 44/50\n",
      "496/496 [==============================] - 0s 196us/step - loss: 0.0043 - acc: 0.9980 - val_loss: 1.1292 - val_acc: 0.8839\n",
      "Epoch 45/50\n",
      "496/496 [==============================] - 0s 204us/step - loss: 0.0071 - acc: 0.9960 - val_loss: 0.9131 - val_acc: 0.9018\n",
      "Epoch 46/50\n",
      "496/496 [==============================] - 0s 205us/step - loss: 0.0119 - acc: 0.9940 - val_loss: 1.1986 - val_acc: 0.8482\n",
      "Epoch 47/50\n",
      "496/496 [==============================] - 0s 205us/step - loss: 2.0714e-04 - acc: 1.0000 - val_loss: 0.9566 - val_acc: 0.8839\n",
      "Epoch 48/50\n",
      "496/496 [==============================] - 0s 206us/step - loss: 0.0281 - acc: 0.9960 - val_loss: 0.9031 - val_acc: 0.9018\n",
      "Epoch 49/50\n",
      "496/496 [==============================] - 0s 204us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.9336 - val_acc: 0.9018\n",
      "Epoch 50/50\n",
      "496/496 [==============================] - 0s 208us/step - loss: 0.0097 - acc: 0.9980 - val_loss: 0.8673 - val_acc: 0.9018\n"
     ]
    }
   ],
   "source": [
    "train_top_model(train_df, test_df, 50, 16, 'eyewear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tune Top Model to improve accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_model(train_df, test_df,epoch, batch_size,label, print_model = True):\n",
    "    # build VGG16 model and freeze top layers\n",
    "    # input_shape: width, height, RGB (from image generator)\n",
    "    model_vgg = VGG16(weights='imagenet',include_top=False, input_shape=(150,150,3))\n",
    "    # build top model\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=model_vgg.output_shape[1:]))\n",
    "    top_model.add(Dense(256,activation='relu'))\n",
    "    top_model.add(Dropout(0.5))\n",
    "    top_model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # load saved weights to fine tune parameters \n",
    "    top_model.load_weights('../tuning_data/bottleneck_vgg_model_eyewears.h5')\n",
    "    # add top model to model\n",
    "    model = Model(inputs=model_vgg.input, outputs=top_model(model_vgg.output))\n",
    "    # we will tune last 5 layers of the model: block5 and fully connected layer \n",
    "    for layer in model.layers[:15]:\n",
    "        layer.trainable = False\n",
    "    # we can tune the parameters for lr and momentum later to get better results\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "             optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "             metrics=['accuracy'])\n",
    "    # prepare train generator using data augmentation to battle small sample size \n",
    "    train_gen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "    # not want to augment the test \n",
    "    test_gen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    train_generator =  train_gen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory='../data/pics',\n",
    "    x_col='pic_id',\n",
    "    y_col=label,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(150,150),\n",
    "    class_mode = 'binary')\n",
    "    \n",
    "    test_generator =  test_gen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory='../data/pics',\n",
    "    x_col='pic_id',\n",
    "    y_col=label,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(150,150),\n",
    "    class_mode = 'binary')\n",
    "    \n",
    "    # run and fit model \n",
    "    history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_df.shape[0]//batch_size,\n",
    "    epochs=epoch,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_df.shape[0]//batch_size,\n",
    "    verbose=1)\n",
    "    \n",
    "    if print_model:\n",
    "        model.summary()\n",
    "    return history    \n",
    "\n",
    "    del model\n",
    "    keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save model history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0829 11:01:40.319553 139794952161088 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0829 11:01:40.320737 139794952161088 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0829 11:01:40.322682 139794952161088 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0829 11:01:40.337631 139794952161088 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0829 11:01:40.944281 139794952161088 deprecation.py:506] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0829 11:01:41.026478 139794952161088 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0829 11:01:41.030820 139794952161088 deprecation.py:323] From /home/mindy/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 505 validated image filenames belonging to 2 classes.\n",
      "Found 127 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 3.2631 - acc: 0.3923 - val_loss: 0.7050 - val_acc: 0.4554\n",
      "Epoch 2/50\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.7269 - acc: 0.5265 - val_loss: 0.6429 - val_acc: 0.7117\n",
      "Epoch 3/50\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.6946 - acc: 0.5698 - val_loss: 0.6532 - val_acc: 0.6667\n",
      "Epoch 4/50\n",
      "31/31 [==============================] - 4s 137ms/step - loss: 0.6706 - acc: 0.6011 - val_loss: 0.6326 - val_acc: 0.6847\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - 4s 131ms/step - loss: 0.6318 - acc: 0.6727 - val_loss: 0.5915 - val_acc: 0.7117\n",
      "Epoch 6/50\n",
      "31/31 [==============================] - 4s 125ms/step - loss: 0.6335 - acc: 0.6525 - val_loss: 0.5959 - val_acc: 0.7027\n",
      "Epoch 7/50\n",
      "31/31 [==============================] - 4s 118ms/step - loss: 0.6044 - acc: 0.6813 - val_loss: 0.4890 - val_acc: 0.8559\n",
      "Epoch 8/50\n",
      "31/31 [==============================] - 4s 125ms/step - loss: 0.5432 - acc: 0.7514 - val_loss: 0.4729 - val_acc: 0.8288\n",
      "Epoch 9/50\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.4928 - acc: 0.8069 - val_loss: 0.4042 - val_acc: 0.8482\n",
      "Epoch 10/50\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 0.4510 - acc: 0.8250 - val_loss: 0.3527 - val_acc: 0.9009\n",
      "Epoch 11/50\n",
      "31/31 [==============================] - 4s 127ms/step - loss: 0.3837 - acc: 0.8669 - val_loss: 0.3968 - val_acc: 0.8468\n",
      "Epoch 12/50\n",
      "31/31 [==============================] - 4s 129ms/step - loss: 0.4193 - acc: 0.8270 - val_loss: 0.2872 - val_acc: 0.8919\n",
      "Epoch 13/50\n",
      "31/31 [==============================] - 4s 124ms/step - loss: 0.3162 - acc: 0.8710 - val_loss: 0.2837 - val_acc: 0.8919\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - 4s 126ms/step - loss: 0.3496 - acc: 0.8577 - val_loss: 0.2163 - val_acc: 0.9640\n",
      "Epoch 15/50\n",
      "31/31 [==============================] - 4s 124ms/step - loss: 0.3285 - acc: 0.8690 - val_loss: 0.2343 - val_acc: 0.9459\n",
      "Epoch 16/50\n",
      "31/31 [==============================] - 4s 119ms/step - loss: 0.2637 - acc: 0.9092 - val_loss: 0.2533 - val_acc: 0.8919\n",
      "Epoch 17/50\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.2431 - acc: 0.9092 - val_loss: 0.2111 - val_acc: 0.9464\n",
      "Epoch 18/50\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 0.2658 - acc: 0.9032 - val_loss: 0.2265 - val_acc: 0.9189\n",
      "Epoch 19/50\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.2582 - acc: 0.9067 - val_loss: 0.1971 - val_acc: 0.9369\n",
      "Epoch 20/50\n",
      "31/31 [==============================] - 4s 131ms/step - loss: 0.2214 - acc: 0.9254 - val_loss: 0.1929 - val_acc: 0.9189\n",
      "Epoch 21/50\n",
      "31/31 [==============================] - 4s 118ms/step - loss: 0.2298 - acc: 0.9153 - val_loss: 0.2287 - val_acc: 0.8739\n",
      "Epoch 22/50\n",
      "31/31 [==============================] - 4s 130ms/step - loss: 0.2713 - acc: 0.9072 - val_loss: 0.3762 - val_acc: 0.8018\n",
      "Epoch 23/50\n",
      "31/31 [==============================] - 4s 121ms/step - loss: 0.2247 - acc: 0.9036 - val_loss: 0.1557 - val_acc: 0.9459\n",
      "Epoch 24/50\n",
      "31/31 [==============================] - 4s 127ms/step - loss: 0.2230 - acc: 0.9032 - val_loss: 0.2299 - val_acc: 0.9099\n",
      "Epoch 25/50\n",
      "31/31 [==============================] - 4s 129ms/step - loss: 0.1811 - acc: 0.9254 - val_loss: 0.2471 - val_acc: 0.8750\n",
      "Epoch 26/50\n",
      "31/31 [==============================] - 5s 152ms/step - loss: 0.1853 - acc: 0.9254 - val_loss: 0.1102 - val_acc: 0.9730\n",
      "Epoch 27/50\n",
      "31/31 [==============================] - 4s 125ms/step - loss: 0.1398 - acc: 0.9516 - val_loss: 0.1917 - val_acc: 0.9369\n",
      "Epoch 28/50\n",
      "31/31 [==============================] - 4s 126ms/step - loss: 0.1646 - acc: 0.9516 - val_loss: 0.1187 - val_acc: 0.9640\n",
      "Epoch 29/50\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.1590 - acc: 0.9455 - val_loss: 0.2179 - val_acc: 0.9279\n",
      "Epoch 30/50\n",
      "31/31 [==============================] - 4s 129ms/step - loss: 0.1460 - acc: 0.9455 - val_loss: 0.1534 - val_acc: 0.9550\n",
      "Epoch 31/50\n",
      "31/31 [==============================] - 4s 121ms/step - loss: 0.1349 - acc: 0.9642 - val_loss: 0.1374 - val_acc: 0.9550\n",
      "Epoch 32/50\n",
      "31/31 [==============================] - 4s 125ms/step - loss: 0.1446 - acc: 0.9536 - val_loss: 0.1455 - val_acc: 0.9459\n",
      "Epoch 33/50\n",
      "31/31 [==============================] - 4s 129ms/step - loss: 0.1236 - acc: 0.9481 - val_loss: 0.0895 - val_acc: 0.9732\n",
      "Epoch 34/50\n",
      "31/31 [==============================] - 5s 151ms/step - loss: 0.1265 - acc: 0.9597 - val_loss: 0.1820 - val_acc: 0.9369\n",
      "Epoch 35/50\n",
      "31/31 [==============================] - 4s 145ms/step - loss: 0.0894 - acc: 0.9677 - val_loss: 0.1912 - val_acc: 0.9369\n",
      "Epoch 36/50\n",
      "31/31 [==============================] - 4s 127ms/step - loss: 0.1338 - acc: 0.9476 - val_loss: 0.1425 - val_acc: 0.9459\n",
      "Epoch 37/50\n",
      "31/31 [==============================] - 4s 134ms/step - loss: 0.0986 - acc: 0.9718 - val_loss: 0.0966 - val_acc: 0.9640\n",
      "Epoch 38/50\n",
      "31/31 [==============================] - 4s 124ms/step - loss: 0.0935 - acc: 0.9738 - val_loss: 0.1725 - val_acc: 0.9369\n",
      "Epoch 39/50\n",
      "31/31 [==============================] - 4s 125ms/step - loss: 0.1131 - acc: 0.9637 - val_loss: 0.1237 - val_acc: 0.9640\n",
      "Epoch 40/50\n",
      "31/31 [==============================] - 4s 128ms/step - loss: 0.1060 - acc: 0.9738 - val_loss: 0.1381 - val_acc: 0.9459\n",
      "Epoch 41/50\n",
      "31/31 [==============================] - 4s 120ms/step - loss: 0.0959 - acc: 0.9637 - val_loss: 0.1639 - val_acc: 0.9375\n",
      "Epoch 42/50\n",
      "31/31 [==============================] - 5s 155ms/step - loss: 0.0847 - acc: 0.9738 - val_loss: 0.1097 - val_acc: 0.9640\n",
      "Epoch 43/50\n",
      "31/31 [==============================] - 4s 129ms/step - loss: 0.0752 - acc: 0.9859 - val_loss: 0.1488 - val_acc: 0.9279\n",
      "Epoch 44/50\n",
      "31/31 [==============================] - 4s 128ms/step - loss: 0.0605 - acc: 0.9844 - val_loss: 0.1307 - val_acc: 0.9640\n",
      "Epoch 45/50\n",
      "31/31 [==============================] - 4s 125ms/step - loss: 0.0683 - acc: 0.9819 - val_loss: 0.1593 - val_acc: 0.9459\n",
      "Epoch 46/50\n",
      "31/31 [==============================] - 4s 131ms/step - loss: 0.0664 - acc: 0.9778 - val_loss: 0.0425 - val_acc: 0.9910\n",
      "Epoch 47/50\n",
      "31/31 [==============================] - 4s 129ms/step - loss: 0.0527 - acc: 0.9818 - val_loss: 0.1417 - val_acc: 0.9550\n",
      "Epoch 48/50\n",
      "31/31 [==============================] - 4s 113ms/step - loss: 0.0608 - acc: 0.9778 - val_loss: 0.1792 - val_acc: 0.9369\n",
      "Epoch 49/50\n",
      "31/31 [==============================] - 4s 131ms/step - loss: 0.0594 - acc: 0.9818 - val_loss: 0.1402 - val_acc: 0.9554\n",
      "Epoch 50/50\n",
      "31/31 [==============================] - 4s 143ms/step - loss: 0.0477 - acc: 0.9879 - val_loss: 0.1150 - val_acc: 0.9640\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 2097665   \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 9,177,089\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_history = fine_tune_model(train_df, test_df,50,16,'eyewear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest test accuracy: 0.990990990990991\n",
      "------------------\n",
      "highest train accuracy: 0.9879032258064516\n"
     ]
    }
   ],
   "source": [
    "highest_val_acc, highest_train_acc = max(model_history.history['val_acc']), max(model_history.history['acc'])\n",
    "print(f'highest test accuracy: {highest_val_acc}')\n",
    "print('------------------')\n",
    "print(f'highest train accuracy: {highest_train_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowest test loss: 0.0580780416525699\n",
      "------------------\n",
      "lowest train loss: 0.055970603133530826\n"
     ]
    }
   ],
   "source": [
    "lowest_val_loss, lowest_train_loss = min(model_history.history['val_loss']), min(model_history.history['loss'])\n",
    "print(f'lowest test loss: {lowest_val_loss}')\n",
    "print('------------------')\n",
    "print(f'lowest train loss: {lowest_train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_history.history['val_acc'], color = 'red', label = 'test')\n",
    "plt.plot(model_history.history['acc'], color = 'blue', label = 'train')\n",
    "plt.title('accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_history.history['val_loss'], color = 'red', label = 'test')\n",
    "plt.plot(model_history.history['loss'], color = 'blue', label = 'train')\n",
    "plt.title('loss')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
