{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning Tuning_EyeWear:\n",
    "  * model parameter and other information can be found below:\n",
    "     * [source](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)\n",
    "     \n",
    "  * base_model: use vgg16 and freeze at bottleneck layer (stop right before flatten layer) \n",
    "  * top_model: tune dense layers (parameters are inspired by source)\n",
    "     * batch_size 16 seems to work best for small data set \n",
    "\n",
    "##### warnings: make sure to restart kernel in between running different model tuning \n",
    "  \n",
    "---\n",
    "#### This cell is required in order to use GPU for running the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0829 13:09:13.096470 139973435746112 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0829 13:09:13.097342 139973435746112 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "                                    # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
    "keras.backend.get_session().run(tf.global_variables_initializer())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import optimizers\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Import train_df and test_df for eyewears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('../pickle_files/train_df_glasses.pkl')\n",
    "test_df = pd.read_pickle('../pickle_files/test_df_glasses.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get bottleneck features to tune top models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_bottleneck_features(train_df, test_df, label, batch_size):\n",
    "    '''\n",
    "    inputs:\n",
    "    train_df, test_df: train and test dataframes saved in pickle_files folder\n",
    "    label: a string, eyewear, hat, or beard\n",
    "    batch_size: process images in batches\n",
    "    outputs:\n",
    "    saves bottleneck features inside folder tuning_data as npy file\n",
    "    '''\n",
    "    # intialize the vgg16 model \n",
    "    # make sure not to train the top layers \n",
    "    base_model = VGG16(weights = 'imagenet', include_top = False)\n",
    "    # create train_generator and test_generator to get bottleneck inputs for train and test df \n",
    "    datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "    # make sure shuffle is False so we know the label follows the sequence of the dataframe \n",
    "    # so we can tune top_model \n",
    "    train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory='../data/pics',\n",
    "    x_col='pic_id',\n",
    "    y_col=label,\n",
    "    batch_size=batch_size,\n",
    "    shuffle = False,\n",
    "    target_size=(150,150),\n",
    "    class_mode = None)\n",
    "    # get features saved as .npy in tunign_data folder \n",
    "    bottleneck_features_train = base_model.predict_generator(\n",
    "        train_generator, train_df.shape[0]//batch_size)\n",
    "    np.save(open('../tuning_data/bottleneck_features_train_eyewears.npy','wb'),\n",
    "           bottleneck_features_train)\n",
    "    \n",
    "    test_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory='../data/pics',\n",
    "    x_col='pic_id',\n",
    "    y_col=label,\n",
    "    batch_size=batch_size,\n",
    "    shuffle = False,\n",
    "    target_size=(150,150),\n",
    "    class_mode = None)\n",
    "    bottleneck_features_test = base_model.predict_generator(\n",
    "        test_generator, test_df.shape[0]//batch_size)\n",
    "    np.save(open('../tuning_data/bottleneck_features_test_eyewears.npy','wb'),\n",
    "           bottleneck_features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save bottleneck_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0829 13:09:37.756263 139973435746112 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0829 13:09:37.757290 139973435746112 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0829 13:09:37.759651 139973435746112 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0829 13:09:37.775812 139973435746112 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 505 validated image filenames.\n",
      "Found 127 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "save_bottleneck_features(train_df,test_df,'eyewear',16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick tuning of top models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_top_model(train_df, test_df, epoch, batch_size, label):\n",
    "    '''\n",
    "    inputs:\n",
    "    train_df, test_df: dataframes saved in pickle_files to generate train and test labels \n",
    "    epoch: num of epochs in fit \n",
    "    batch_size: same as image generator batch size \n",
    "    label: a string, eyewear, hat, or beard\n",
    "    output:\n",
    "    saves model weights in a folder \n",
    "    '''\n",
    "    train_data = np.load(open('../tuning_data/bottleneck_features_train_eyewears.npy','rb'))\n",
    "    # make sure train_data and train_label have same num of samples\n",
    "    train_label = np.array(train_df[label].map({'not_'+label:0, label:1}))[:-(train_df.shape[0]%batch_size)]\n",
    "    \n",
    "    test_data = np.load(open('../tuning_data/bottleneck_features_test_eyewears.npy','rb'))\n",
    "    test_label = np.array(test_df[label].map({'not_'+label:0, label:1}))[:-(test_df.shape[0]%batch_size)]\n",
    "    \n",
    "    # build top model\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # compile model \n",
    "    model.compile(optimizer='rmsprop',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    # checkpoint for best weights \n",
    "    filepath=\"../tuning_data/best_bottleneck_vgg_model_eyewears.h5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    \n",
    "    # fit model \n",
    "    model.fit(train_data, train_label,\n",
    "             epochs=epoch,\n",
    "             batch_size=batch_size,\n",
    "             validation_data=(test_data,test_label),\n",
    "             callbacks=callbacks_list)\n",
    "    del model\n",
    "    keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run train_top_model and save results in tuning_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0829 13:14:31.956500 139973435746112 deprecation.py:506] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0829 13:14:31.969187 139973435746112 deprecation_wrapper.py:119] From /home/mindy/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0829 13:14:31.978829 139973435746112 deprecation.py:323] From /home/mindy/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 496 samples, validate on 112 samples\n",
      "Epoch 1/50\n",
      "496/496 [==============================] - 0s 856us/step - loss: 1.4105 - acc: 0.6815 - val_loss: 0.3433 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.87500, saving model to ../tuning_data/best_bottleneck_vgg_model_eyewears.h5\n",
      "Epoch 2/50\n",
      "496/496 [==============================] - 0s 187us/step - loss: 0.5911 - acc: 0.7480 - val_loss: 0.6156 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.87500\n",
      "Epoch 3/50\n",
      "496/496 [==============================] - 0s 191us/step - loss: 0.4228 - acc: 0.8105 - val_loss: 0.3239 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.87500\n",
      "Epoch 4/50\n",
      "496/496 [==============================] - 0s 185us/step - loss: 0.3086 - acc: 0.8790 - val_loss: 0.4189 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.87500\n",
      "Epoch 5/50\n",
      "496/496 [==============================] - 0s 186us/step - loss: 0.3204 - acc: 0.8871 - val_loss: 0.3882 - val_acc: 0.8304\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.87500\n",
      "Epoch 6/50\n",
      "496/496 [==============================] - 0s 212us/step - loss: 0.1903 - acc: 0.9274 - val_loss: 1.0930 - val_acc: 0.7411\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.87500\n",
      "Epoch 7/50\n",
      "496/496 [==============================] - 0s 205us/step - loss: 0.1990 - acc: 0.9153 - val_loss: 1.7908 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.87500\n",
      "Epoch 8/50\n",
      "496/496 [==============================] - 0s 196us/step - loss: 0.1658 - acc: 0.9375 - val_loss: 0.5317 - val_acc: 0.8482\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.87500\n",
      "Epoch 9/50\n",
      "496/496 [==============================] - 0s 191us/step - loss: 0.1005 - acc: 0.9657 - val_loss: 0.5736 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.87500\n",
      "Epoch 10/50\n",
      "496/496 [==============================] - 0s 201us/step - loss: 0.1161 - acc: 0.9496 - val_loss: 0.5100 - val_acc: 0.8482\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.87500\n",
      "Epoch 11/50\n",
      "496/496 [==============================] - 0s 204us/step - loss: 0.1125 - acc: 0.9577 - val_loss: 0.5259 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.87500\n",
      "Epoch 12/50\n",
      "496/496 [==============================] - 0s 204us/step - loss: 0.1194 - acc: 0.9556 - val_loss: 0.5914 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.87500\n",
      "Epoch 13/50\n",
      "496/496 [==============================] - 0s 195us/step - loss: 0.0389 - acc: 0.9899 - val_loss: 0.6449 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.87500\n",
      "Epoch 14/50\n",
      "496/496 [==============================] - 0s 188us/step - loss: 0.1462 - acc: 0.9536 - val_loss: 0.5840 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.87500 to 0.89286, saving model to ../tuning_data/best_bottleneck_vgg_model_eyewears.h5\n",
      "Epoch 15/50\n",
      "496/496 [==============================] - 0s 192us/step - loss: 0.0284 - acc: 0.9859 - val_loss: 0.5313 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.89286\n",
      "Epoch 16/50\n",
      "496/496 [==============================] - 0s 191us/step - loss: 0.0416 - acc: 0.9758 - val_loss: 0.6341 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.89286\n",
      "Epoch 17/50\n",
      "496/496 [==============================] - 0s 193us/step - loss: 0.0498 - acc: 0.9819 - val_loss: 0.7776 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.89286\n",
      "Epoch 18/50\n",
      "496/496 [==============================] - 0s 195us/step - loss: 0.0280 - acc: 0.9899 - val_loss: 0.6820 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.89286\n",
      "Epoch 19/50\n",
      "496/496 [==============================] - 0s 184us/step - loss: 0.0440 - acc: 0.9879 - val_loss: 1.3807 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.89286\n",
      "Epoch 20/50\n",
      "496/496 [==============================] - 0s 191us/step - loss: 0.0160 - acc: 0.9919 - val_loss: 0.7237 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.89286\n",
      "Epoch 21/50\n",
      "496/496 [==============================] - 0s 189us/step - loss: 0.1077 - acc: 0.9718 - val_loss: 0.7544 - val_acc: 0.8839\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.89286\n",
      "Epoch 22/50\n",
      "496/496 [==============================] - 0s 186us/step - loss: 0.0109 - acc: 0.9960 - val_loss: 0.7619 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.89286\n",
      "Epoch 23/50\n",
      "496/496 [==============================] - 0s 185us/step - loss: 0.0424 - acc: 0.9899 - val_loss: 0.7195 - val_acc: 0.8839\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.89286\n",
      "Epoch 24/50\n",
      "496/496 [==============================] - 0s 189us/step - loss: 0.0227 - acc: 0.9919 - val_loss: 0.7463 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.89286\n",
      "Epoch 25/50\n",
      "496/496 [==============================] - 0s 185us/step - loss: 0.0069 - acc: 0.9960 - val_loss: 1.0926 - val_acc: 0.8393\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.89286\n",
      "Epoch 26/50\n",
      "496/496 [==============================] - 0s 179us/step - loss: 0.0240 - acc: 0.9919 - val_loss: 0.9394 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.89286\n",
      "Epoch 27/50\n",
      "496/496 [==============================] - 0s 189us/step - loss: 0.0257 - acc: 0.9919 - val_loss: 0.7878 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.89286\n",
      "Epoch 28/50\n",
      "496/496 [==============================] - 0s 189us/step - loss: 6.6366e-04 - acc: 1.0000 - val_loss: 0.8282 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.89286\n",
      "Epoch 29/50\n",
      "496/496 [==============================] - 0s 189us/step - loss: 0.0246 - acc: 0.9980 - val_loss: 0.7718 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.89286\n",
      "Epoch 30/50\n",
      "496/496 [==============================] - 0s 191us/step - loss: 0.0023 - acc: 0.9980 - val_loss: 0.7445 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.89286\n",
      "Epoch 31/50\n",
      "496/496 [==============================] - 0s 190us/step - loss: 0.0414 - acc: 0.9919 - val_loss: 0.8079 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.89286\n",
      "Epoch 32/50\n",
      "496/496 [==============================] - 0s 192us/step - loss: 0.0076 - acc: 0.9960 - val_loss: 0.8729 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.89286\n",
      "Epoch 33/50\n",
      "496/496 [==============================] - 0s 189us/step - loss: 4.5749e-04 - acc: 1.0000 - val_loss: 1.0347 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.89286\n",
      "Epoch 34/50\n",
      "496/496 [==============================] - 0s 198us/step - loss: 0.0132 - acc: 0.9960 - val_loss: 0.8764 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.89286\n",
      "Epoch 35/50\n",
      "496/496 [==============================] - 0s 187us/step - loss: 0.0040 - acc: 0.9980 - val_loss: 0.7666 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.89286\n",
      "Epoch 36/50\n",
      "496/496 [==============================] - 0s 188us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.9051 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.89286\n",
      "Epoch 37/50\n",
      "496/496 [==============================] - 0s 186us/step - loss: 0.0256 - acc: 0.9879 - val_loss: 0.9158 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.89286\n",
      "Epoch 38/50\n",
      "496/496 [==============================] - 0s 185us/step - loss: 0.0076 - acc: 0.9940 - val_loss: 0.8667 - val_acc: 0.8839\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.89286\n",
      "Epoch 39/50\n",
      "496/496 [==============================] - 0s 188us/step - loss: 0.0171 - acc: 0.9960 - val_loss: 0.8856 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.89286\n",
      "Epoch 40/50\n",
      "496/496 [==============================] - 0s 195us/step - loss: 0.0098 - acc: 0.9960 - val_loss: 0.8686 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.89286 to 0.90179, saving model to ../tuning_data/best_bottleneck_vgg_model_eyewears.h5\n",
      "Epoch 41/50\n",
      "496/496 [==============================] - 0s 193us/step - loss: 6.4193e-04 - acc: 1.0000 - val_loss: 0.9809 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.90179\n",
      "Epoch 42/50\n",
      "496/496 [==============================] - 0s 191us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.9295 - val_acc: 0.8839\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.90179\n",
      "Epoch 43/50\n",
      "496/496 [==============================] - 0s 192us/step - loss: 0.0048 - acc: 0.9980 - val_loss: 1.0538 - val_acc: 0.8661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00043: val_acc did not improve from 0.90179\n",
      "Epoch 44/50\n",
      "496/496 [==============================] - 0s 192us/step - loss: 2.0233e-04 - acc: 1.0000 - val_loss: 0.9848 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.90179\n",
      "Epoch 45/50\n",
      "496/496 [==============================] - 0s 184us/step - loss: 0.0081 - acc: 0.9960 - val_loss: 0.9262 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.90179\n",
      "Epoch 46/50\n",
      "496/496 [==============================] - 0s 194us/step - loss: 6.8509e-05 - acc: 1.0000 - val_loss: 1.0472 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.90179\n",
      "Epoch 47/50\n",
      "496/496 [==============================] - 0s 190us/step - loss: 0.0179 - acc: 0.9940 - val_loss: 1.0086 - val_acc: 0.8839\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.90179\n",
      "Epoch 48/50\n",
      "496/496 [==============================] - 0s 187us/step - loss: 2.2579e-05 - acc: 1.0000 - val_loss: 1.0318 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.90179\n",
      "Epoch 49/50\n",
      "496/496 [==============================] - 0s 188us/step - loss: 0.0213 - acc: 0.9940 - val_loss: 1.1670 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.90179\n",
      "Epoch 50/50\n",
      "496/496 [==============================] - 0s 194us/step - loss: 3.9645e-04 - acc: 1.0000 - val_loss: 1.0513 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.90179\n"
     ]
    }
   ],
   "source": [
    "train_top_model(train_df, test_df, 50, 16, 'eyewear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tune Top Model to improve accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_model(train_df, test_df,epoch, batch_size,label, print_model = True):\n",
    "    # build VGG16 model and freeze top layers\n",
    "    # input_shape: width, height, RGB (from image generator)\n",
    "    model_vgg = VGG16(weights='imagenet',include_top=False, input_shape=(150,150,3))\n",
    "    # build top model\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=model_vgg.output_shape[1:]))\n",
    "    top_model.add(Dense(256,activation='relu'))\n",
    "    top_model.add(Dropout(0.5))\n",
    "    top_model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # load saved weights to fine tune parameters \n",
    "    top_model.load_weights('../tuning_data/best_bottleneck_vgg_model_eyewears.h5')\n",
    "    # add top model to model\n",
    "    model = Model(inputs=model_vgg.input, outputs=top_model(model_vgg.output))\n",
    "    # we will tune last 5 layers of the model: block5 and fully connected layer \n",
    "    for layer in model.layers[:15]:\n",
    "        layer.trainable = False\n",
    "    # we can tune the parameters for lr and momentum later to get better results\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "             optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "             metrics=['accuracy'])\n",
    "    # prepare train generator using data augmentation to battle small sample size \n",
    "    train_gen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "    # not want to augment the test \n",
    "    test_gen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    train_generator =  train_gen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory='../data/pics',\n",
    "    x_col='pic_id',\n",
    "    y_col=label,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(150,150),\n",
    "    class_mode = 'binary')\n",
    "    \n",
    "    test_generator =  test_gen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory='../data/pics',\n",
    "    x_col='pic_id',\n",
    "    y_col=label,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(150,150),\n",
    "    class_mode = 'binary')\n",
    "    \n",
    "    # checkpoint for best weights \n",
    "    filepath=\"../tuning_data/best_vgg_model_eyewears.h5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    \n",
    "    # run and fit model \n",
    "    result = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_df.shape[0]//batch_size,\n",
    "    epochs=epoch,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_df.shape[0]//batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list)\n",
    "    \n",
    "    if print_model:\n",
    "        model.summary()\n",
    "        \n",
    "    del model\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    return result      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save model history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 505 validated image filenames belonging to 2 classes.\n",
      "Found 127 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "31/31 [==============================] - 4s 140ms/step - loss: 3.3521 - acc: 0.4534 - val_loss: 0.7704 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.50000, saving model to ../tuning_data/best_vgg_model_eyewears.h5\n",
      "Epoch 2/50\n",
      "31/31 [==============================] - 5s 154ms/step - loss: 0.7543 - acc: 0.5121 - val_loss: 0.6528 - val_acc: 0.6216\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.50000 to 0.62162, saving model to ../tuning_data/best_vgg_model_eyewears.h5\n",
      "Epoch 3/50\n",
      "31/31 [==============================] - 5s 146ms/step - loss: 0.6781 - acc: 0.5885 - val_loss: 0.6431 - val_acc: 0.6036\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.62162\n",
      "Epoch 4/50\n",
      "31/31 [==============================] - 4s 137ms/step - loss: 0.6406 - acc: 0.6170 - val_loss: 0.5403 - val_acc: 0.7748\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.62162 to 0.77477, saving model to ../tuning_data/best_vgg_model_eyewears.h5\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - 4s 142ms/step - loss: 0.5898 - acc: 0.7040 - val_loss: 0.5188 - val_acc: 0.8198\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.77477 to 0.81982, saving model to ../tuning_data/best_vgg_model_eyewears.h5\n",
      "Epoch 6/50\n",
      "31/31 [==============================] - 4s 126ms/step - loss: 0.5854 - acc: 0.6687 - val_loss: 0.6078 - val_acc: 0.6126\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.81982\n",
      "Epoch 7/50\n",
      "31/31 [==============================] - 4s 138ms/step - loss: 0.5170 - acc: 0.7580 - val_loss: 0.4211 - val_acc: 0.8739\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.81982 to 0.87387, saving model to ../tuning_data/best_vgg_model_eyewears.h5\n",
      "Epoch 8/50\n",
      "31/31 [==============================] - 3s 105ms/step - loss: 0.4336 - acc: 0.8270 - val_loss: 0.3459 - val_acc: 0.8919\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.87387 to 0.89189, saving model to ../tuning_data/best_vgg_model_eyewears.h5\n",
      "Epoch 9/50\n",
      "31/31 [==============================] - 4s 144ms/step - loss: 0.4157 - acc: 0.8407 - val_loss: 0.3120 - val_acc: 0.9107\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.89189 to 0.91071, saving model to ../tuning_data/best_vgg_model_eyewears.h5\n",
      "Epoch 10/50\n",
      "31/31 [==============================] - 4s 141ms/step - loss: 0.3630 - acc: 0.8613 - val_loss: 0.2593 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.91071 to 0.91892, saving model to ../tuning_data/best_vgg_model_eyewears.h5\n",
      "Epoch 11/50\n",
      "31/31 [==============================] - 4s 124ms/step - loss: 0.3363 - acc: 0.8633 - val_loss: 0.3215 - val_acc: 0.8288\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.91892\n",
      "Epoch 12/50\n",
      "31/31 [==============================] - 4s 116ms/step - loss: 0.3326 - acc: 0.8754 - val_loss: 0.2364 - val_acc: 0.9009\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.91892\n",
      "Epoch 13/50\n",
      "31/31 [==============================] - 4s 145ms/step - loss: 0.2916 - acc: 0.8831 - val_loss: 0.2137 - val_acc: 0.9009\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.91892\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - 4s 124ms/step - loss: 0.2740 - acc: 0.8790 - val_loss: 0.1870 - val_acc: 0.9369\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.91892 to 0.93694, saving model to ../tuning_data/best_vgg_model_eyewears.h5\n",
      "Epoch 15/50\n",
      "31/31 [==============================] - 4s 118ms/step - loss: 0.2657 - acc: 0.8941 - val_loss: 0.1782 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.93694\n",
      "Epoch 16/50\n",
      "31/31 [==============================] - 4s 136ms/step - loss: 0.2478 - acc: 0.9052 - val_loss: 0.1834 - val_acc: 0.9369\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.93694\n",
      "Epoch 17/50\n",
      "31/31 [==============================] - 4s 135ms/step - loss: 0.2483 - acc: 0.8996 - val_loss: 0.1682 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.93694 to 0.93750, saving model to ../tuning_data/best_vgg_model_eyewears.h5\n",
      "Epoch 18/50\n",
      "31/31 [==============================] - 5s 146ms/step - loss: 0.2358 - acc: 0.9153 - val_loss: 0.1802 - val_acc: 0.9369\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.93750\n",
      "Epoch 19/50\n",
      "31/31 [==============================] - 4s 113ms/step - loss: 0.2350 - acc: 0.9157 - val_loss: 0.1401 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.93750 to 0.97297, saving model to ../tuning_data/best_vgg_model_eyewears.h5\n",
      "Epoch 20/50\n",
      "31/31 [==============================] - 4s 133ms/step - loss: 0.2009 - acc: 0.9234 - val_loss: 0.1677 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.97297\n",
      "Epoch 21/50\n",
      "31/31 [==============================] - 4s 138ms/step - loss: 0.2046 - acc: 0.9198 - val_loss: 0.1593 - val_acc: 0.9369\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.97297\n",
      "Epoch 22/50\n",
      "31/31 [==============================] - 4s 130ms/step - loss: 0.2068 - acc: 0.9254 - val_loss: 0.0882 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.97297\n",
      "Epoch 23/50\n",
      "31/31 [==============================] - 4s 131ms/step - loss: 0.1949 - acc: 0.9253 - val_loss: 0.1772 - val_acc: 0.9369\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.97297\n",
      "Epoch 24/50\n",
      "31/31 [==============================] - 4s 118ms/step - loss: 0.1434 - acc: 0.9637 - val_loss: 0.1184 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.97297\n",
      "Epoch 25/50\n",
      "31/31 [==============================] - 4s 130ms/step - loss: 0.2115 - acc: 0.9234 - val_loss: 0.1202 - val_acc: 0.9643\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.97297\n",
      "Epoch 26/50\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.1622 - acc: 0.9395 - val_loss: 0.1305 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.97297\n",
      "Epoch 27/50\n",
      "31/31 [==============================] - 4s 138ms/step - loss: 0.1387 - acc: 0.9597 - val_loss: 0.0744 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.97297 to 0.99099, saving model to ../tuning_data/best_vgg_model_eyewears.h5\n",
      "Epoch 28/50\n",
      "31/31 [==============================] - 4s 127ms/step - loss: 0.1455 - acc: 0.9460 - val_loss: 0.1382 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.99099\n",
      "Epoch 29/50\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.1498 - acc: 0.9476 - val_loss: 0.0763 - val_acc: 0.9550\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.99099\n",
      "Epoch 30/50\n",
      "31/31 [==============================] - 4s 138ms/step - loss: 0.1397 - acc: 0.9516 - val_loss: 0.1117 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.99099\n",
      "Epoch 31/50\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 0.1196 - acc: 0.9597 - val_loss: 0.1174 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.99099\n",
      "Epoch 32/50\n",
      "31/31 [==============================] - 4s 127ms/step - loss: 0.1499 - acc: 0.9455 - val_loss: 0.1189 - val_acc: 0.9550\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.99099\n",
      "Epoch 33/50\n",
      "31/31 [==============================] - 4s 133ms/step - loss: 0.1308 - acc: 0.9597 - val_loss: 0.0996 - val_acc: 0.9643\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.99099\n",
      "Epoch 34/50\n",
      "31/31 [==============================] - 5s 148ms/step - loss: 0.1360 - acc: 0.9516 - val_loss: 0.1426 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.99099\n",
      "Epoch 35/50\n",
      "31/31 [==============================] - 5s 149ms/step - loss: 0.1479 - acc: 0.9481 - val_loss: 0.2004 - val_acc: 0.9369\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.99099\n",
      "Epoch 36/50\n",
      "31/31 [==============================] - 4s 139ms/step - loss: 0.1169 - acc: 0.9516 - val_loss: 0.1112 - val_acc: 0.9550\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.99099\n",
      "Epoch 37/50\n",
      "31/31 [==============================] - 4s 130ms/step - loss: 0.1291 - acc: 0.9637 - val_loss: 0.1615 - val_acc: 0.9550\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.99099\n",
      "Epoch 38/50\n",
      "31/31 [==============================] - 4s 135ms/step - loss: 0.1106 - acc: 0.9617 - val_loss: 0.1143 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.99099\n",
      "Epoch 39/50\n",
      "31/31 [==============================] - 4s 131ms/step - loss: 0.0829 - acc: 0.9702 - val_loss: 0.1141 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.99099\n",
      "Epoch 40/50\n",
      "31/31 [==============================] - 4s 119ms/step - loss: 0.1065 - acc: 0.9738 - val_loss: 0.1283 - val_acc: 0.9550\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.99099\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 4s 134ms/step - loss: 0.1244 - acc: 0.9476 - val_loss: 0.1243 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.99099\n",
      "Epoch 42/50\n",
      "31/31 [==============================] - 5s 151ms/step - loss: 0.0947 - acc: 0.9677 - val_loss: 0.2124 - val_acc: 0.9550\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.99099\n",
      "Epoch 43/50\n",
      "31/31 [==============================] - 4s 122ms/step - loss: 0.1132 - acc: 0.9496 - val_loss: 0.1642 - val_acc: 0.9369\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.99099\n",
      "Epoch 44/50\n",
      "31/31 [==============================] - 4s 127ms/step - loss: 0.1169 - acc: 0.9496 - val_loss: 0.1455 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.99099\n",
      "Epoch 45/50\n",
      "31/31 [==============================] - 4s 138ms/step - loss: 0.0804 - acc: 0.9763 - val_loss: 0.1397 - val_acc: 0.9550\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.99099\n",
      "Epoch 46/50\n",
      "31/31 [==============================] - 4s 126ms/step - loss: 0.0755 - acc: 0.9718 - val_loss: 0.1380 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.99099\n",
      "Epoch 47/50\n",
      "31/31 [==============================] - 4s 134ms/step - loss: 0.0755 - acc: 0.9738 - val_loss: 0.1037 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.99099\n",
      "Epoch 48/50\n",
      "31/31 [==============================] - 3s 112ms/step - loss: 0.0549 - acc: 0.9839 - val_loss: 0.1183 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.99099\n",
      "Epoch 49/50\n",
      "31/31 [==============================] - 4s 136ms/step - loss: 0.0652 - acc: 0.9798 - val_loss: 0.1447 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.99099\n",
      "Epoch 50/50\n",
      "31/31 [==============================] - 5s 147ms/step - loss: 0.0532 - acc: 0.9859 - val_loss: 0.1233 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.99099\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 2097665   \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 9,177,089\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_history = fine_tune_model(train_df, test_df,50,16,'eyewear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest test accuracy: 0.990990990990991\n",
      "------------------\n",
      "highest train accuracy: 0.9858870967741935\n"
     ]
    }
   ],
   "source": [
    "highest_val_acc, highest_train_acc = max(model_history.history['val_acc']), max(model_history.history['acc'])\n",
    "print(f'highest test accuracy: {highest_val_acc}')\n",
    "print('------------------')\n",
    "print(f'highest train accuracy: {highest_train_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowest test loss: 0.07439137790519912\n",
      "------------------\n",
      "lowest train loss: 0.053185363179974014\n"
     ]
    }
   ],
   "source": [
    "lowest_val_loss, lowest_train_loss = min(model_history.history['val_loss']), min(model_history.history['loss'])\n",
    "print(f'lowest test loss: {lowest_val_loss}')\n",
    "print('------------------')\n",
    "print(f'lowest train loss: {lowest_train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_history.history['val_acc'], color = 'red', label = 'test')\n",
    "plt.plot(model_history.history['acc'], color = 'blue', label = 'train')\n",
    "plt.title('accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_history.history['val_loss'], color = 'red', label = 'test')\n",
    "plt.plot(model_history.history['loss'], color = 'blue', label = 'train')\n",
    "plt.title('loss')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model artchitecture \n",
    "eyewear_model = model_history.model\n",
    "eyewear_model_json = eyewear_model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "with open(\"eyewear_model.json\", \"w\") as json_file:\n",
    "    json_file.write(eyewear_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open('eyewear_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model_eyewear = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model weight \n",
    "loaded_model_eyewear.load_weights('../tuning_data/best_vgg_model_eyewears.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 127 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator =  test_gen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory='../data/pics',\n",
    "    x_col='pic_id',\n",
    "    y_col='eyewear',\n",
    "    batch_size=16,\n",
    "    target_size=(150,150),\n",
    "    class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_eyewear.compile(loss='binary_crossentropy',\n",
    "             optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.11282623422838102, 0.9763779527559056]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model_eyewear.evaluate_generator(test_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
