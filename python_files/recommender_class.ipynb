{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) < 2:\n",
    "        print('Wrong input. Please enter a folder path.')\n",
    "        sys.exit(1)\n",
    "    filepaths = sys.argv[1:]\n",
    "    for filepath in filepaths:\n",
    "        recommend(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import libaries\n",
    "import os\n",
    "# disable tensorflow logging\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import face_recognition\n",
    "from keras_preprocessing.image import load_img, img_to_array\n",
    "from keras.models import model_from_json\n",
    "from keras.applications.resnet50 import preprocess_input as rs50\n",
    "from vgg16_preprocess import preprocess_input as vgp\n",
    "from PIL import Image as pil_image\n",
    "#~ import warnings\n",
    "#~ warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.backend.tensorflow_backend import set_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable tensorflow logging\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# allows the computer to use GPU to run the model\n",
    "config = tf.ConfigProto()\n",
    "# dynamically grow the memory used on the GPU, necessary for RTX cards\n",
    "config.gpu_options.allow_growth = True\n",
    "# to log device placement (on which device the operation ran)\n",
    "config.log_device_placement = False\n",
    "sess = tf.Session(config=config)\n",
    "# set this TensorFlow session as the default session for Keras\n",
    "set_session(sess)\n",
    "keras.backend.get_session().run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductRecommender:\n",
    "    def __init__(self):\n",
    "        self.vgg_16 = []\n",
    "        self.resnet = []\n",
    "\n",
    "    def load_model(self, vgg16_model, resnet_model, weight_lists):\n",
    "        \"\"\"\n",
    "         # Arguments\n",
    "             resnet_model, vgg16_model: json model path for resnet50 and vgg16.\n",
    "              weight_lists: nested file path to saved best weights as h5.\n",
    "        \"\"\"\n",
    "        # load json and create model and load weights \n",
    "        for i, model in enumerate([vgg16_model, resnet_model]):\n",
    "            for weight in weight_lists[i]: # vgg first then resnet\n",
    "                # vgg first \n",
    "                if not i:\n",
    "                    json_file = open(model, 'r')\n",
    "                    loaded_model_json = json_file.read()\n",
    "                    json_file.close()\n",
    "                    loaded_model = model_from_json(loaded_model_json)\n",
    "                    # eyewear, beard, hat\n",
    "                    loaded_model.load_weights(weight)\n",
    "                    self.vgg_16.append(loaded_model)\n",
    "                else:\n",
    "                    json_file = open(model, 'r')\n",
    "                    loaded_model_json = json_file.read()\n",
    "                    json_file.close()\n",
    "                    loaded_model = model_from_json(loaded_model_json)\n",
    "                    # eyewear, beard, hat\n",
    "                    loaded_model.load_weights(weight)\n",
    "                    self.resnet.append(loaded_model)\n",
    "\n",
    "    def cropping(self, file_path):\n",
    "        \"\"\"Crops faces from a pic.\n",
    "        # Arguments\n",
    "            file_path: file_path to each pic.\n",
    "        # Returns\n",
    "            a list of cropped images of faces for each pic.\n",
    "        \"\"\"\n",
    "        # load pic\n",
    "        pic = face_recognition.load_image_file(file_path)\n",
    "        # obtain list of images with tuples, 4 points\n",
    "        # (ymin,xmax,ymax,xmin)\n",
    "        face_locations = face_recognition.face_locations(pic)\n",
    "        # intialize an empty list of available faces\n",
    "        faces = []\n",
    "        for loc in face_locations:\n",
    "            delta_y = loc[2] - loc[0]\n",
    "            delta_x = loc[1] - loc[3]\n",
    "            # experimented to find a good width for hats and beard\n",
    "            y_width = 2.5*delta_y\n",
    "            x_increase = int((y_width*0.7 - delta_x)/2)\n",
    "            y_increase = 1.25*delta_y/2\n",
    "            y_min = loc[0]-int(y_increase)\n",
    "            y_max = loc[2]+int(y_increase*0.4)\n",
    "            x_min = loc[3]-x_increase\n",
    "            x_max = loc[1]+x_increase\n",
    "            # make sure not to go out of range\n",
    "            if x_min < 0:\n",
    "                x_min = 0\n",
    "            if x_max > pic.shape[1]:\n",
    "                x_max = pic.shape[1]\n",
    "            if y_min < 0:\n",
    "                y_min = 0\n",
    "            if y_max > pic.shape[0]:\n",
    "                y_max = pic.shape[0]\n",
    "            faces.append(pic[y_min:y_max, x_min:x_max, :])\n",
    "        return faces\n",
    "\n",
    "    def plot_image(self, imagepath):\n",
    "        '''\n",
    "        inputs:\n",
    "        imagepath: path to image \n",
    "        returns:\n",
    "        plot image\n",
    "        '''\n",
    "        img = load_img(imagepath, target_size=(512, 512))\n",
    "        img = img_to_array(img)\n",
    "        img = img/255\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "\n",
    "    def recommend(self, filepath):\n",
    "        \"\"\"recommends most relevant product to each IG user picture folder.\n",
    "           Products are eyewear, hat, and beard.\n",
    "        # Arguments\n",
    "             filepath: IG user picture folder file path.\n",
    "        \"\"\"\n",
    "        if os.path.isfile(filepath):\n",
    "            files = [filepath]\n",
    "        else:\n",
    "            files = [os.path.join(filepath, file)\n",
    "                     for file in os.listdir(filepath) if file != '.DS_Store']\n",
    "        # keep track of num eyewear, beard, hat, and total pic with faces cropped\n",
    "        eyewear = 0\n",
    "        beard = 0\n",
    "        hat = 0\n",
    "        total = 0\n",
    "        # sequence of eyewear, beard, and hat\n",
    "        highest_score = [0, 0, 0]\n",
    "        highest_image = ['', '', '']\n",
    "        for file in files:\n",
    "            if len(files) == 1:  # just one image:\n",
    "                print('Actual Image:')\n",
    "                self.plot_image(file)\n",
    "                plt.show(block=False)\n",
    "                plt.pause(5)\n",
    "                plt.close()\n",
    "            faces = self.cropping(file)\n",
    "            if not faces:\n",
    "                if len(files) == 1:\n",
    "                    print('No face detected')\n",
    "                continue\n",
    "            total += 1\n",
    "            for face in faces:\n",
    "                # remove identified false faces\n",
    "                # assume the fake faces are less than 150 pixel\n",
    "                if len(files) == 1:\n",
    "                    print('After crop:')\n",
    "                    plt.imshow(face)\n",
    "                    plt.axis('off')\n",
    "                    plt.show(block=False)\n",
    "                    plt.pause(5)\n",
    "                    plt.close()\n",
    "                if face.shape[0] <= 150 or face.shape[1] <= 150:\n",
    "                    continue\n",
    "                    print(f'Analyzing image number {total}...')\n",
    "                # get predicted value for both resnet50 and vgg16\n",
    "                # vgg16 predictions first:\n",
    "                img_v = pil_image.fromarray(face).resize((150, 150),\n",
    "                                                         pil_image.NEAREST)\n",
    "                img_v = np.expand_dims(img_v, axis=0)\n",
    "                img_v = vgp(img_v)\n",
    "                img_v = img_v/255\n",
    "                # follow this exact sequence: eyewear, beard, hat\n",
    "                preds_v = []\n",
    "                for model in self.vgg_16:\n",
    "                    pred_v = model.predict(img_v)[0][0]\n",
    "                    preds_v.append(pred_v)\n",
    "                # resnet50 predictions\n",
    "                img_r = pil_image.fromarray(face).resize(\n",
    "                    (224, 224), pil_image.NEAREST)\n",
    "                img_r = np.expand_dims(img_r, axis=0)\n",
    "                img_r = rs50(img_r)\n",
    "                preds_r = []\n",
    "                for model in self.resnet:\n",
    "                    pred_r = model.predict(img_r)[0][0]\n",
    "                    preds_r.append(pred_r)\n",
    "                # average the two value as an ensemble method\n",
    "                pred_c = np.array([preds_v, preds_r]).mean(axis=0)\n",
    "                # update highest scores\n",
    "                # decide if each image has eyewear, beard or hat\n",
    "                if pred_c[0] >= 0.5:\n",
    "                    eyewear += 1\n",
    "                if pred_c[0] > highest_score[0]:\n",
    "                    highest_image[0] = file\n",
    "                    highest_score[0] = pred_c[0]\n",
    "                if pred_c[1] >= 0.5:\n",
    "                    beard += 1\n",
    "                if pred_c[1] > highest_score[1]:\n",
    "                    highest_image[1] = file\n",
    "                    highest_score[1] = pred_c[1]\n",
    "                if pred_c[2] >= 0.5:\n",
    "                    hat += 1\n",
    "                if pred_c[2] > highest_score[2]:\n",
    "                    highest_image[2] = file\n",
    "                    highest_score[2] = pred_c[2]\n",
    "            # recommend products based upon most percentage per total num of pics\n",
    "            # make sure total is not zero\n",
    "        if total:\n",
    "            index = np.argmax([eyewear/total, beard/total, hat/total])\n",
    "            product = ['eyewear', 'beard', 'hat'][index]\n",
    "            img_chosen = highest_image[index]\n",
    "            self.plot_image(img_chosen)\n",
    "            plt.title(f\"We recommend {product} products to this IG user!\")\n",
    "            plt.show(block=False)\n",
    "            plt.pause(3)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the 6 models outside the recommend function to speed up process:\n",
    "model_path_v = '../tuning_data/VGG_16_tuning/vgg_model.json'\n",
    "file_path_v = '../tuning_data/VGG_16_tuning/'\n",
    "eyewear_v = file_path_v+'best_vgg16_model_eyewear.h5'\n",
    "hat_v = file_path_v+'best_vgg16_model_hat.h5'\n",
    "beard_v = file_path_v+'best_vgg16_model_beard.h5'\n",
    "model_path_r = '../tuning_data/resnet_data/resnet50_model_5_up.json'\n",
    "file_path_r = '../tuning_data/resnet_data/untracked_resnet50/'\n",
    "eyewear_r = file_path_r+'best_resnet50_model_eyewear.h5'\n",
    "hat_r = file_path_r+'best_resnet50_model_hat.h5'\n",
    "beard_r = file_path_r+'best_resnet50_model_beard.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = ProductRecommender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1.load_model(model_path_v, model_path_r, [\n",
    "                  [eyewear_v, beard_v, hat_v], [eyewear_r,beard_r,hat_r]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1.recommend('../data/IG_photo/becca_k/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
